{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:06:53.408122Z",
     "iopub.status.busy": "2022-05-20T23:06:53.407759Z",
     "iopub.status.idle": "2022-05-20T23:06:53.948805Z",
     "shell.execute_reply": "2022-05-20T23:06:53.947555Z",
     "shell.execute_reply.started": "2022-05-20T23:06:53.408094Z"
    },
    "id": "H5QntWoelAkH",
    "outputId": "31efe7df-24ff-40e8-8517-0c7174968413"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/ubiquant/lib/python3.9/site-packages/lofo/lofo_importance.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import eli5\n",
    "import lofo\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "import difflib\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode\n",
    "import multiprocessing\n",
    "from tqdm.auto import tqdm\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "from BorutaShap import BorutaShap\n",
    "from sklearn.metrics import f1_score, fbeta_score, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold, StratifiedGroupKFold\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"lightgbm\")\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 13\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = Namespace(\n",
    "    train = True,\n",
    "    full = False,\n",
    "    debug = False,\n",
    "    optimize = True,\n",
    "    select_features = False,\n",
    "    selection_type = 'corr', # feasible values: lofo, perm, shap, corr, gain\n",
    "    test = False,\n",
    "    folds = 0,\n",
    "    seed = 42,\n",
    "    pos_frac = 0,\n",
    "    target = 'label',\n",
    "    threshold = 0.5,\n",
    "    train_path = 'train_dataset',\n",
    "    model_dir = 'fsq_lgbm_models',\n",
    "    es_rounds = 50\n",
    ")\n",
    "\n",
    "bad_features = ['text_sim'] + ['main_categories_te', 'city_decoded_te', 'categories_te', 'country_te'] + ['main_categories_vc', 'city_decoded_vc', 'categories_vc', 'country_vc']\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "## Load train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:06:53.950215Z",
     "iopub.status.busy": "2022-05-20T23:06:53.949976Z",
     "iopub.status.idle": "2022-05-20T23:06:59.622657Z",
     "shell.execute_reply": "2022-05-20T23:06:59.621792Z",
     "shell.execute_reply.started": "2022-05-20T23:06:53.950187Z"
    },
    "id": "wz7JepVilAkN",
    "outputId": "0652de28-9bd3-4ab7-c97c-55e6e11935e6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20b3e8efa4354344bfc6961672ee18c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "def downcast_floats(df):\n",
    "    floats = ['float32', 'float64']\n",
    "    float_features = list(df.select_dtypes(include=floats).columns)\n",
    "    for f in float_features:\n",
    "        df[f] = df[f].astype('float16')\n",
    "    return df\n",
    "    \n",
    "if CFG.full or CFG.folds:\n",
    "    train_files = glob(os.path.join(CFG.train_path, \"train_*.parquet\"))\n",
    "    valid_files = glob(os.path.join(CFG.train_path, \"valid_*.parquet\"))\n",
    "    train_files = train_files + valid_files\n",
    "else:\n",
    "    train_files = glob(os.path.join(CFG.train_path, \"train_*.parquet\"))\n",
    "\n",
    "train = list()\n",
    "for filename in tqdm(train_files):\n",
    "    # load data\n",
    "    df = pd.read_parquet(filename)\n",
    "    \n",
    "    # set features\n",
    "    features = list(df.select_dtypes(include=numerics).columns)\n",
    "    features.remove(CFG.target)\n",
    "    \n",
    "    if CFG.debug:\n",
    "        df = df.sample(n = 10000, random_state = CFG.seed)\n",
    "        df = df.reset_index(drop = True)\n",
    "    df = downcast_floats(df)\n",
    "    train.append(df)\n",
    "\n",
    "train = pd.concat(train, axis=0, ignore_index=True)\n",
    "\n",
    "train['kdist'] = train['kdist'].fillna(train['kdist_country'])\n",
    "train['kdist_country'] = train['kdist_country'].fillna(train['kdist'])\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35f874193bc7482db607cafd24f4bc69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not CFG.full and not CFG.folds:\n",
    "    valid_files = glob(os.path.join(CFG.train_path, \"valid_*.parquet\"))\n",
    "\n",
    "    valid = list()\n",
    "    for filename in tqdm(valid_files):\n",
    "        # load data\n",
    "        df = pd.read_parquet(filename)\n",
    "        # set features\n",
    "        features = list(df.select_dtypes(include=numerics).columns)\n",
    "        features.remove(CFG.target)\n",
    "        \n",
    "        if CFG.debug:\n",
    "            df = df.sample(n = 10000, random_state = CFG.seed)\n",
    "            df = df.reset_index(drop = True)\n",
    "        df = downcast_floats(df)\n",
    "        valid.append(df)\n",
    "\n",
    "    valid = pd.concat(valid, axis=0, ignore_index=True)\n",
    "\n",
    "    valid['kdist'] = valid['kdist'].fillna(valid['kdist_country'])\n",
    "    valid['kdist_country'] = valid['kdist_country'].fillna(valid['kdist'])\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the rest matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not CFG.full and not CFG.folds:\n",
    "#     all_matches_files = glob(os.path.join(CFG.train_path, \"all_matches_*.parquet\"))\n",
    "    \n",
    "#     all_matches = list()\n",
    "#     for filename in tqdm(all_matches_files):\n",
    "#         df = pd.read_parquet(filename)\n",
    "#         if CFG.debug:\n",
    "#             df = df.sample(n = 10000, random_state = CFG.seed)\n",
    "#             df = df.reset_index(drop = True)\n",
    "#         df = downcast_floats(df)\n",
    "#         all_matches.append(df)\n",
    "\n",
    "#     all_matches = pd.concat(all_matches, axis=0, ignore_index=True)\n",
    "    \n",
    "    \n",
    "# all_matches['label'] = 1\n",
    "# all_matches = all_matches[all_matches['id'] != all_matches['match_id']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add matches to train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# all_matches_ids = set(all_matches['id'].unique())\n",
    "\n",
    "# train_ids = set(train['id'].unique())\n",
    "# all_matches_train_ids = list(train_ids.intersection(all_matches_ids))\n",
    "\n",
    "# if not CFG.full and not CFG.folds:\n",
    "#     valid_ids = set(valid['id'].unique())\n",
    "#     all_matches_valid_ids = list(valid_ids.intersection(all_matches_ids))\n",
    "\n",
    "# all_matches = all_matches.set_index('id')\n",
    "# all_matches_train = all_matches.loc[all_matches_train_ids]\n",
    "# all_matches_train = all_matches_train.reset_index()\n",
    "# train = pd.concat([train, all_matches_train], axis=0, ignore_index=True)\n",
    "# train = train.drop_duplicates(['id', 'match_id'])\n",
    "# del train_ids, all_matches_ids, all_matches_train_ids\n",
    "\n",
    "# if not CFG.full and not CFG.folds:\n",
    "#     all_matches_valid = all_matches.loc[all_matches_valid_ids]\n",
    "#     all_matches_valid = all_matches_valid.reset_index()\n",
    "#     valid = pd.concat([valid, all_matches_valid], axis=0, ignore_index=True)\n",
    "#     valid = valid.drop_duplicates(['id', 'match_id'])\n",
    "#     del valid_ids, all_matches_valid_ids, all_matches_valid\n",
    "\n",
    "# del all_matches, all_matches_train\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase fraction of positive targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2 µs, sys: 1 µs, total: 3 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if CFG.pos_frac:\n",
    "    train_pos_index = train[train['label'] == 1].index\n",
    "    train_neg_index = train[train['label'] == 0].index\n",
    "    train_neg_index = np.random.choice(train_neg_index, size=int(len(train_pos_index)*((1-CFG.pos_frac)/CFG.pos_frac)))\n",
    "    train_pos_index = np.concatenate([train_pos_index, train_neg_index])\n",
    "    np.random.shuffle(train_pos_index)\n",
    "    train = train.loc[train_pos_index].reset_index(drop=True)\n",
    "    del train_pos_index, train_neg_index\n",
    "    gc.collect()\n",
    "\n",
    "    if not CFG.full and not CFG.folds:\n",
    "        valid_pos_index = valid[valid['label'] == 1].index\n",
    "        valid_neg_index = valid[valid['label'] == 0].index\n",
    "        valid_neg_index = np.random.choice(valid_neg_index, size=int(len(valid_pos_index)*((1-CFG.pos_frac)/CFG.pos_frac)))\n",
    "        valid_pos_index = np.concatenate([valid_pos_index, valid_neg_index])\n",
    "        np.random.shuffle(valid_pos_index)\n",
    "        valid = valid.loc[valid_pos_index].reset_index(drop=True)\n",
    "        del valid_pos_index, valid_neg_index\n",
    "        gc.collect() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Drop bad features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if bad_features:\n",
    "    train = train.drop(bad_features, axis=1)\n",
    "    if not CFG.full and not CFG.folds:\n",
    "        valid = valid.drop(bad_features, axis=1)\n",
    "    for f in bad_features:\n",
    "        features.remove(f)\n",
    "        \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset by folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.folds > 0:\n",
    "    kf = StratifiedGroupKFold(n_splits=CFG.folds, shuffle=True, random_state=CFG.seed)\n",
    "    for i, (trn_idx, val_idx) in tqdm(enumerate(kf.split(train, train[\"label\"], train[\"id\"]))):\n",
    "        train.loc[val_idx, \"fold\"] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-19 12:37:39,289]\u001b[0m A new study created in memory with name: no-name-f152b86c-0e02-4fba-81ea-9d088ceb3b3d\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.99284\n",
      "[200]\tvalid_0's auc: 0.993092\n",
      "[300]\tvalid_0's auc: 0.993185\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[296]\tvalid_0's auc: 0.993186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-19 12:53:24,079]\u001b[0m Trial 0 finished with value: 0.9931859538457324 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.10004951803381777, 'lambda_l1': 1.1314188547416955e-07, 'lambda_l2': 1.3913200302937685e-05, 'num_leaves': 214, 'max_bin': 162, 'feature_fraction': 0.5432595795095669, 'bagging_fraction': 0.5654056931776374, 'bagging_freq': 6, 'min_child_samples': 62, 'min_sum_hessian_in_leaf': 0.062014166639611325}. Best is trial 0 with value: 0.9931859538457324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.988857\n",
      "[200]\tvalid_0's auc: 0.989891\n",
      "[300]\tvalid_0's auc: 0.990659\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.990659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-19 13:07:27,428]\u001b[0m Trial 1 finished with value: 0.9906587780644746 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.009186596187905877, 'lambda_l1': 0.03668989971358215, 'lambda_l2': 5.8466895187326795, 'num_leaves': 100, 'max_bin': 177, 'feature_fraction': 0.41950027723877675, 'bagging_fraction': 0.9016507264931654, 'bagging_freq': 1, 'min_child_samples': 37, 'min_sum_hessian_in_leaf': 0.09466005539904067}. Best is trial 0 with value: 0.9931859538457324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.988732\n",
      "[200]\tvalid_0's auc: 0.989748\n",
      "[300]\tvalid_0's auc: 0.990548\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.990548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-19 13:22:46,683]\u001b[0m Trial 2 finished with value: 0.9905482940335918 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.007615292094901635, 'lambda_l1': 0.347733110095675, 'lambda_l2': 4.826131967459972e-05, 'num_leaves': 185, 'max_bin': 105, 'feature_fraction': 0.7508316736623503, 'bagging_fraction': 0.8933627966990414, 'bagging_freq': 4, 'min_child_samples': 41, 'min_sum_hessian_in_leaf': 0.07612104627235977}. Best is trial 0 with value: 0.9931859538457324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.988694\n",
      "[200]\tvalid_0's auc: 0.989709\n",
      "[300]\tvalid_0's auc: 0.990273\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.990273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-19 13:37:31,816]\u001b[0m Trial 3 finished with value: 0.9902728797254972 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.006237581565606524, 'lambda_l1': 4.675311171728331e-06, 'lambda_l2': 0.001130973876577991, 'num_leaves': 179, 'max_bin': 77, 'feature_fraction': 0.646212767102985, 'bagging_fraction': 0.905818155588652, 'bagging_freq': 4, 'min_child_samples': 64, 'min_sum_hessian_in_leaf': 0.046425116351134346}. Best is trial 0 with value: 0.9931859538457324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.988623\n",
      "[200]\tvalid_0's auc: 0.989361\n",
      "[300]\tvalid_0's auc: 0.989846\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.989846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-19 13:50:23,193]\u001b[0m Trial 4 finished with value: 0.9898461367245553 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.003814445509142491, 'lambda_l1': 0.0001228165164517989, 'lambda_l2': 0.7315135619904908, 'num_leaves': 169, 'max_bin': 155, 'feature_fraction': 0.4725725835931315, 'bagging_fraction': 0.5217881202465326, 'bagging_freq': 1, 'min_child_samples': 13, 'min_sum_hessian_in_leaf': 0.021463939375485908}. Best is trial 0 with value: 0.9931859538457324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.985943\n",
      "[200]\tvalid_0's auc: 0.987978\n",
      "[300]\tvalid_0's auc: 0.98887\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.98887\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-19 14:01:51,497]\u001b[0m Trial 5 finished with value: 0.9888695534789962 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.004094627778282805, 'lambda_l1': 6.311473328883248e-07, 'lambda_l2': 0.13954072426335165, 'num_leaves': 134, 'max_bin': 231, 'feature_fraction': 0.8800930434222787, 'bagging_fraction': 0.7096779098929258, 'bagging_freq': 6, 'min_child_samples': 57, 'min_sum_hessian_in_leaf': 0.06893846654806618}. Best is trial 0 with value: 0.9931859538457324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[46]\tvalid_0's auc: 0.991891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-19 14:07:16,253]\u001b[0m Trial 6 finished with value: 0.9918908813273462 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.13875721932561777, 'lambda_l1': 0.00018893687572404892, 'lambda_l2': 1.3625128377372447e-06, 'num_leaves': 253, 'max_bin': 119, 'feature_fraction': 0.9109771750880176, 'bagging_fraction': 0.749581797460271, 'bagging_freq': 6, 'min_child_samples': 12, 'min_sum_hessian_in_leaf': 0.015143891394664682}. Best is trial 0 with value: 0.9931859538457324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.992412\n",
      "Early stopping, best iteration is:\n",
      "[77]\tvalid_0's auc: 0.992623\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-19 14:14:39,029]\u001b[0m Trial 7 finished with value: 0.9926230202353975 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.13846726791513625, 'lambda_l1': 1.7028908972727315, 'lambda_l2': 3.0582119990359434e-07, 'num_leaves': 136, 'max_bin': 189, 'feature_fraction': 0.4020444778209793, 'bagging_fraction': 0.9928425657019126, 'bagging_freq': 4, 'min_child_samples': 30, 'min_sum_hessian_in_leaf': 0.015543522693083473}. Best is trial 0 with value: 0.9931859538457324.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.992643\n",
      "[200]\tvalid_0's auc: 0.993291\n",
      "[300]\tvalid_0's auc: 0.993442\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.993442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-19 14:31:39,202]\u001b[0m Trial 8 finished with value: 0.9934420824158684 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.06412538431756477, 'lambda_l1': 0.5075360165194788, 'lambda_l2': 2.1181029181051983e-07, 'num_leaves': 240, 'max_bin': 133, 'feature_fraction': 0.9401108993466838, 'bagging_fraction': 0.842829737558284, 'bagging_freq': 3, 'min_child_samples': 58, 'min_sum_hessian_in_leaf': 0.05798770200720065}. Best is trial 8 with value: 0.9934420824158684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.992706\n",
      "[200]\tvalid_0's auc: 0.99333\n",
      "[300]\tvalid_0's auc: 0.993442\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[300]\tvalid_0's auc: 0.993442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-06-19 14:46:36,818]\u001b[0m Trial 9 finished with value: 0.9934420196592714 and parameters: {'boosting_type': 'gbdt', 'learning_rate': 0.07046907775298634, 'lambda_l1': 0.5275446153443103, 'lambda_l2': 0.03315437976194136, 'num_leaves': 231, 'max_bin': 146, 'feature_fraction': 0.5088425783894458, 'bagging_fraction': 0.4685956731814398, 'bagging_freq': 3, 'min_child_samples': 51, 'min_sum_hessian_in_leaf': 0.046049126977302124}. Best is trial 8 with value: 0.9934420824158684.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[100]\tvalid_0's auc: 0.94314\n",
      "[200]\tvalid_0's auc: 0.949908\n"
     ]
    }
   ],
   "source": [
    "# FYI: Objective functions can take additional arguments\n",
    "# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n",
    "global global_preds\n",
    "\n",
    "def objective(trial):\n",
    "    global global_preds\n",
    "    dtrain = lgb.Dataset(train[features], label=train[CFG.target])\n",
    "    dvalid = lgb.Dataset(valid[features], label=valid[CFG.target])\n",
    "\n",
    "    param = {\n",
    "        'seed': CFG.seed,\n",
    "#         'device': 'gpu',\n",
    "#         'gpu_platform_id': 0,\n",
    "#         'gpu_device_id': 0,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': trial.suggest_categorical(\"boosting_type\", ['gbdt']),# 'dart', 'goss']),\n",
    "        'force_col_wise': False, # Use only with CPU devices\n",
    "        'subsample_for_bin': 300000, # Number of data that sampled to construct feature discrete bins; setting this \n",
    "                                     # to larger value will give better training result but may increase train time\n",
    "        'n_estimators': 300, #trial.suggest_int('n_estimators', 300, 1000),      \n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 3e-1),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256), # Max number of leaves in one tree\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255), # Max number of bins that feature values will be \n",
    "                                                           # bucketed in. small number of bins may reduce training \n",
    "                                                           # accuracy but may deal with overfitting\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0), # Randomly select a subset of features \n",
    "                                                                               # if feature_fraction < 1.0\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0), # Randomly select part of data without \n",
    "                                                                               # resampling if bagging_fraction < 1.0\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7), # Perform bagging at every k iteration\n",
    "        'min_data_in_leaf': trial.suggest_int('min_child_samples', 5, 64), # Minimal number of data in one leaf\n",
    "                                                                            # aliases: min_child_samples, \n",
    "        'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 1e-4, 1e-1), # Stop trying to split \n",
    "                                                                                               # leave if sum of it's\n",
    "                                                                                               # hessian less than k\n",
    "#         'cat_smooth': trial.suggest_float('cat_smooth', 10.0, 100.0), # this can reduce the effect of noises in \n",
    "#                                                                       # categorical features, especially for \n",
    "#                                                                       # categories with few data\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'auc')\n",
    "    gbm = lgb.train(\n",
    "        param, \n",
    "        dtrain, \n",
    "        valid_sets=[dvalid],\n",
    "        callbacks = [lgb.log_evaluation(100), \n",
    "                     lgb.early_stopping(stopping_rounds=50)]\n",
    "    )\n",
    "\n",
    "    # Evaluation\n",
    "    preds = gbm.predict(valid[features])\n",
    "    global_preds = preds\n",
    "    roc_auc = roc_auc_score(valid[CFG.target], preds)\n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "if CFG.optimize:\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\"\n",
    "    )\n",
    "    study.optimize(objective, timeout=9*3600)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "        \n",
    "    # Save study to dataframe\n",
    "    study_df = study.trials_dataframe()\n",
    "    study_df.to_csv('optuna_lgbm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.where(y_hat < 0.5, 0, 1)  \n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "def lgb_f2_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.where(y_hat < 0.5, 0, 1)  \n",
    "    return 'f2', fbeta_score(y_true, y_hat, beta=2), True\n",
    "\n",
    "def fit_lgbm(X_train, y_train, X_val, y_val, init_model=None, \n",
    "             params=None, es_rounds=50, num_iter=0):\n",
    "    train_dataset = lgb.Dataset(X_train, y_train)\n",
    "    valid_dataset = lgb.Dataset(X_val, y_val)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set = train_dataset, \n",
    "        valid_sets = [train_dataset, valid_dataset],\n",
    "        init_model = init_model,\n",
    "        callbacks = [lgb.log_evaluation(10), \n",
    "                     lgb.early_stopping(stopping_rounds=es_rounds),\n",
    "                    ]\n",
    "        )\n",
    "\n",
    "    file = f'{CFG.model_dir}/lgbm.pkl'\n",
    "    pickle.dump(model, open(file, 'wb'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def fit_lgbm_folds(X, y, folds, init_model=None, params=None, es_rounds=50, num_iter=0):\n",
    "    models = []\n",
    "    \n",
    "    for i in tqdm(range(CFG.folds)):\n",
    "        print(f\"== fold {i} ==\")\n",
    "        trn_idx = folds != i\n",
    "        val_idx = folds == i\n",
    "    \n",
    "        train_dataset = lgb.Dataset(X.iloc[trn_idx], y.iloc[trn_idx])\n",
    "        valid_dataset = lgb.Dataset(X.iloc[val_idx], y.iloc[val_idx])\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set = train_dataset, \n",
    "            valid_sets = [train_dataset, valid_dataset],\n",
    "            init_model = init_model,\n",
    "            callbacks = [lgb.log_evaluation(50), \n",
    "                         lgb.early_stopping(stopping_rounds=es_rounds),\n",
    "                        ]\n",
    "            )\n",
    "\n",
    "        models.append(model)\n",
    "    \n",
    "        file = f'{CFG.model_dir}/lgbm_fold_{i}.pkl'\n",
    "        pickle.dump(model, open(file, 'wb'))\n",
    "\n",
    "    return models\n",
    "\n",
    "def predict_(model, X_val, y_val, threshold):\n",
    "    pred = model.predict(X_val)\n",
    "    return pred\n",
    "\n",
    "def predict_folds(models, X, y, folds, threshold):\n",
    "    oof = np.zeros((len(y)), dtype=np.float64)\n",
    "    \n",
    "    for i in tqdm(range(CFG.folds)):\n",
    "        trn_idx = folds != i\n",
    "        val_idx = folds == i\n",
    "        \n",
    "        pred = models[i].predict(X.iloc[val_idx])\n",
    "        oof[val_idx] = pred\n",
    "    \n",
    "    return oof\n",
    "\n",
    "def show_metrics(pred, threshold, y):\n",
    "    y_hat = np.where(pred < threshold, 0, 1)  \n",
    "    acc = (y_hat == y).mean()\n",
    "    f1 = f1_score(y, y_hat)\n",
    "    f2 = fbeta_score(y, y_hat, beta=2)\n",
    "    return acc, f1, f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best LGBM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = pd.read_csv('optuna_lgbm.csv')\n",
    "# lgb_params.to_pickle('LGBM_Optuna_params.pkl')\n",
    "\n",
    "param_cols = [c for c in lgb_params.columns if c.startswith('params_')]\n",
    "lgb_params = lgb_params.sort_values('value')[param_cols].head(10)\n",
    "\n",
    "best_params = list()\n",
    "\n",
    "def param_to_set(row):\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['seed'] = CFG.seed\n",
    "    row_dict['objective'] = 'binary'\n",
    "    row_dict['metric'] = 'auc'\n",
    "    row_dict['n_estimators'] = 1500\n",
    "    row_dict['verbose'] = -1\n",
    "#     row_dict['device'] = 'gpu'\n",
    "#     row_dict['gpu_platform_id'] = 0\n",
    "#     row_dict['gpu_device_id'] = 0\n",
    "    best_params.append(row_dict)\n",
    "    \n",
    "x = lgb_params.apply(param_to_set, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", module=\"lightgbm\")\n",
    "\n",
    "# params = best_params[0]\n",
    "params = {\n",
    "    'seed': CFG.seed,\n",
    "#     'device': 'gpu',\n",
    "#     'gpu_platform_id': 0,\n",
    "#     'gpu_device_id': 0,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.2,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'max_depth': 7,   \n",
    "    'num_leaves': 35, \n",
    "    'n_estimators': 1500, \n",
    "    'colsample_bytree': 0.9,\n",
    "    'verbose': -1,\n",
    "}  \n",
    "\n",
    "if CFG.test:\n",
    "    params['n_estimators'] = 400\n",
    "    \n",
    "if CFG.select_features:\n",
    "    # extract a sample of the data\n",
    "    train = train.sample(frac=0.1, random_state=CFG.seed)\n",
    "    valid = valid.sample(frac=0.1, random_state=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOFO importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='lofo':\n",
    "    # define the validation scheme\n",
    "    cv = KFold(n_splits=2)\n",
    "    train = pd.concat([train, valid], ignore_index=True)\n",
    "    del valid\n",
    "    gc.collect()\n",
    "    # define the binary target and the features\n",
    "    dataset = lofo.Dataset(df=train, target=CFG.target, features=features)\n",
    "    # define the validation scheme and scorer\n",
    "    lofo_imp = lofo.LOFOImportance(dataset, scoring=\"roc_auc\", cv=cv, model=lgb.LGBMClassifier(**params))\n",
    "    # get the mean and standard deviation of the importances in pandas format\n",
    "    importance_df = lofo_imp.get_importance()\n",
    "    importance_df.to_csv('importance_df.csv')\n",
    "    # plot the means and standard deviations of the importances\n",
    "    lofo.plot_importance(importance_df, figsize=(12, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='perm':   \n",
    "    # fit model\n",
    "    model=lgb.LGBMClassifier(**params)\n",
    "    model.fit(train[features], train[CFG.target], eval_set=(valid[features], valid[CFG.target]))\n",
    "    # get permutation importance\n",
    "    perm = PermutationImportance(model, random_state=CFG.seed).fit(valid[features], valid[CFG.target])\n",
    "    eli5.show_weights(perm, feature_names = features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='perm':   \n",
    "    train[features] = train[features].fillna(-9999)\n",
    "    # fit model\n",
    "    model=lgb.LGBMClassifier(**params)\n",
    "    # calculate importance\n",
    "    feature_selector = BorutaShap(importance_measure='shap', classification=True)\n",
    "    feature_selector.fit(X=train[features], y=train[CFG.target], n_trials=50, sample=False, train_or_test = 'test', normalize=True, verbose=True)\n",
    "    feature_selector.plot(which_features='all', figsize=(16,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='gain':   \n",
    "    train[features] = train[features].fillna(-9999)\n",
    "    # fit model\n",
    "    model=lgb.LGBMClassifier(**params)\n",
    "    # calculate importance\n",
    "    feature_selector = BorutaShap(importance_measure='gini', classification=True)\n",
    "    feature_selector.fit(X=train[features], y=train[CFG.target], n_trials=50, sample=False, train_or_test = 'test', normalize=True, verbose=True)\n",
    "    feature_selector.plot(which_features='all', figsize=(16,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='corr':\n",
    "    features_corr = train.fillna(0).corr()\n",
    "    # transform to low triangle matrix\n",
    "    for i in range(features_corr.shape[0]):\n",
    "        for j in range(features_corr.shape[1]):\n",
    "            if j >= i:\n",
    "                features_corr.iloc[i, j] = 0\n",
    "    # unstack\n",
    "    features_corr = features_corr.abs().unstack()\n",
    "    features_corr = features_corr.reset_index()\n",
    "    # select features with corr > 0 and sort them \n",
    "    features_corr = features_corr[features_corr[0] > 0]\n",
    "    features_corr = features_corr.sort_values(0, kind=\"quicksort\", ascending=False)\n",
    "    display(features_corr.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(f'Train shape is {train.shape}')\n",
    "\n",
    "if CFG.folds and CFG.train:\n",
    "    models = fit_lgbm_folds(train[features], train[CFG.target], folds=train['fold'].values,\n",
    "                            params=params, es_rounds=CFG.es_rounds)\n",
    "elif CFG.full and CFG.train:\n",
    "    model = fit_lgbm(train[features], train[CFG.target], \n",
    "                     train[features], train[CFG.target], \n",
    "                     params=params, es_rounds=CFG.es_rounds)\n",
    "elif CFG.train:\n",
    "    assert train.shape[1] == valid.shape[1]\n",
    "    model = fit_lgbm(train[features], train[CFG.target], \n",
    "                     valid[features], valid[CFG.target], \n",
    "                     params=params, es_rounds=CFG.es_rounds)\n",
    "elif CFG.folds:\n",
    "    model_files = glob(os.path.join(CFG.model_dir, \"lgbm*.pkl\"))\n",
    "    models = list()\n",
    "    for model_file in model_files:\n",
    "        with open(model_file, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "            models.append(model)\n",
    "else:\n",
    "    model_file = f'{CFG.model_dir}/lgbm.pkl'\n",
    "    with open(model_file, 'rb') as f:\n",
    "        model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics for the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "best_thr = 0.5\n",
    "best_cv = 0\n",
    "\n",
    "if CFG.folds:\n",
    "    pred = predict_folds(models, train[features], train[CFG.target], train['fold'].values, best_thr)\n",
    "    acc, f1, f2 = show_metrics(pred, best_thr, train[CFG.target])\n",
    "else:\n",
    "    pred = predict_(model, valid[features], valid[CFG.target], best_thr)      \n",
    "    acc, f1, f2 = show_metrics(pred, best_thr, valid[CFG.target])\n",
    "\n",
    "print(f'Best threshold is {best_thr}, Accuracy is {acc:.6f}, F1 score is {f1:.6f}, F2 score is {f2:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuctions for postprocessing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:07:12.983819Z",
     "iopub.status.busy": "2022-05-20T23:07:12.983027Z",
     "iopub.status.idle": "2022-05-20T23:07:12.994514Z",
     "shell.execute_reply": "2022-05-20T23:07:12.993726Z",
     "shell.execute_reply.started": "2022-05-20T23:07:12.983695Z"
    },
    "id": "yHFNkcnglAkW",
    "outputId": "b886a788-4f08-468b-8050-17e92da005ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_id2poi(input_df: pd.DataFrame) -> dict:\n",
    "    return dict(zip(input_df['id'], input_df['point_of_interest']))\n",
    "\n",
    "def get_poi2ids(input_df: pd.DataFrame) -> dict:\n",
    "    return input_df.groupby('point_of_interest')['id'].apply(set).to_dict()\n",
    "\n",
    "def get_score(input_df: pd.DataFrame):\n",
    "    scores = []\n",
    "    id2poi = get_id2poi(input_df)\n",
    "    poi2ids = get_poi2ids(input_df)\n",
    "    for id_str, matches in zip(input_df['id'].to_numpy(), input_df['matches'].to_numpy()):\n",
    "        targets = poi2ids[id2poi[id_str]]\n",
    "        preds = set(matches.split())\n",
    "        score = len((targets & preds)) / len((targets | preds))\n",
    "        scores.append(score)\n",
    "    scores = np.array(scores)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "def postprocess(df):\n",
    "    id2match = dict(zip(df[\"id\"].values, df[\"matches\"].str.split()))\n",
    "\n",
    "    for match in df[\"matches\"].values:\n",
    "        match = match.split()\n",
    "        if len(match) == 1:        \n",
    "            continue\n",
    "\n",
    "        base = match[0]\n",
    "        for m in match[1:]:\n",
    "            if not base in id2match[m]:\n",
    "                id2match[m].append(base)\n",
    "    df[\"matches\"] = df[\"id\"].map(id2match).map(\" \".join)\n",
    "    \n",
    "    return df \n",
    "\n",
    "def get_matches(df, preds):\n",
    "    match_id = df[\"match_id\"].values\n",
    "    matches = []\n",
    "\n",
    "    for df_id, pred, match_idx in tqdm(zip(df[\"id\"], preds, match_id), total=df.shape[0]):\n",
    "        idx = np.round(pred)\n",
    "        if pred == 1:\n",
    "            matches.append(df_id + \" \" + match_idx)\n",
    "        else:\n",
    "            matches.append(df_id)\n",
    "    \n",
    "    df['matches'] = matches\n",
    "    df = postprocess(df)\n",
    "    \n",
    "    return df[['id', 'matches', 'point_of_interest']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add POI column to validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.full:\n",
    "    data_root = 'foursquare_location_matching'\n",
    "    data = pd.read_csv(os.path.join(data_root, 'train.csv'))[['id', 'point_of_interest']]\n",
    "\n",
    "    if CFG.folds:\n",
    "        valid = train.merge(data, how='left', on='id')\n",
    "    else:\n",
    "        valid = valid.merge(data, how='left', on='id')\n",
    "\n",
    "    del data\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Find best threshold and calculate IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "best_thr = 0.5\n",
    "best_cv = 0\n",
    "\n",
    "if not CFG.full:\n",
    "#     for thr in tqdm(np.arange(0.4, 0.6, 0.01)):\n",
    "#         if thr == 0.5:\n",
    "#             continue\n",
    "    y_hat = np.where(pred < CFG.threshold, 0, 1) \n",
    "    res = get_matches(valid, y_hat)\n",
    "    res = res.drop_duplicates()\n",
    "    cv = get_score(res)\n",
    "    print(f'Threshold is {CFG.threshold:.3f}, score is {cv:.6f}')\n",
    "#     if cv > best_cv:\n",
    "#         best_cv = cv\n",
    "#         best_thr = thr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_importance(model):\n",
    "    importance_df = pd.DataFrame(model.feature_importance(), \n",
    "                                 index=features, \n",
    "                                 columns=['importance'])\\\n",
    "                        .sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    plt.subplots(figsize=(len(features) // 4, 5))\n",
    "    plt.bar(importance_df.index, importance_df.importance)\n",
    "    plt.grid()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_importances(models):\n",
    "    importance_df = pd.DataFrame(models[0].feature_importance(), \n",
    "                                 index=features, \n",
    "                                 columns=['importance'])\\\n",
    "                        .sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    plt.subplots(figsize=(len(features) // 4, 5))\n",
    "    plt.bar(importance_df.index, importance_df.importance)\n",
    "    plt.grid()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "if CFG.folds:\n",
    "    plot_importances(models)\n",
    "else:\n",
    "    plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "# IOU: 0.859097\n",
    "# LB: 0.858\n",
    "\n",
    "# 2 group folds\n",
    "# IOU: 0.859097/0.857005\n",
    "# LB: 0.863\n",
    "\n",
    "# 5-stratified folds\n",
    "# IOU: 0.882\n",
    "# LB: 0.862\n",
    "\n",
    "# 5-stratified group folds\n",
    "# IOU: 0.882\n",
    "# LB: 0.861\n",
    "\n",
    "# 5-stratified group folds, thr 0.43\n",
    "# IOU: 0.883\n",
    "# LB: 0.854\n",
    "\n",
    "# Return cluster feature, n_iter 1429/1183      \n",
    "# IOU: 0.859382/0.859301\n",
    "# LB: 0.865\n",
    "\n",
    "#########################################################################\n",
    "\n",
    "# Test baseline\n",
    "# IOU: 0.854927\n",
    "\n",
    "# Drop bad features\n",
    "# IOU: 0.854878\n",
    "\n",
    "# Add text similarity\n",
    "# IOU: 0.854449\n",
    "\n",
    "# Add all matches to train\n",
    "# IOU: 0.882953\n",
    "\n",
    "# Add text similarity + add all matches to train\n",
    "# IOU: 0.882987\n",
    "\n",
    "# Fill NaNs with -9999\n",
    "# IOU: 0.851635\n",
    "\n",
    "# Baseline with fixed TF-IDF (don' count unknowns)\n",
    "# IOU: 0.854954\n",
    "\n",
    "# Fix haversine distance for KNNs\n",
    "# IOU: 0.856982\n",
    "\n",
    "# Fillna for kdist and kdist_country\n",
    "# IOU: 0.857143\n",
    "\n",
    "# Add text similarity by cleaned columns\n",
    "# IOU: 0.856037\n",
    "\n",
    "# 5-folds\n",
    "# IOU: 0.869376\n",
    "# LB: 0.867\n",
    "\n",
    "# Add Japaneese text\n",
    "# IOU: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
