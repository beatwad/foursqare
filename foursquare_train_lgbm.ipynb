{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:06:53.408122Z",
     "iopub.status.busy": "2022-05-20T23:06:53.407759Z",
     "iopub.status.idle": "2022-05-20T23:06:53.948805Z",
     "shell.execute_reply": "2022-05-20T23:06:53.947555Z",
     "shell.execute_reply.started": "2022-05-20T23:06:53.408094Z"
    },
    "id": "H5QntWoelAkH",
    "outputId": "31efe7df-24ff-40e8-8517-0c7174968413"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/ubiquant/lib/python3.9/site-packages/lofo/lofo_importance.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import eli5\n",
    "import lofo\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "import difflib\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from lightgbm import LGBMClassifier, LGBMRanker\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode\n",
    "import multiprocessing\n",
    "from tqdm.auto import tqdm\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "from BorutaShap import BorutaShap\n",
    "from sklearn.metrics import f1_score, fbeta_score, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "from sklearn.metrics import average_precision_score\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold, StratifiedGroupKFold\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"lightgbm\")\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 13\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = Namespace(\n",
    "    train = False,\n",
    "    full = False,\n",
    "    debug = False,\n",
    "    optimize = False,\n",
    "    select_features = True,\n",
    "    load_params = False,\n",
    "    selection_type = 'lofo', # feasible values: lofo, perm, shap, corr, gain\n",
    "    test = False,\n",
    "    folds = 0,\n",
    "    seed = 42,\n",
    "    pos_frac = 0,\n",
    "    target = 'match',\n",
    "    threshold = 0.5,\n",
    "    train_path = 'train_dataset',\n",
    "    model_dir = 'fsq_lgbm_models',\n",
    "    es_rounds = 50\n",
    ")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "## Load dataset utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:06:53.950215Z",
     "iopub.status.busy": "2022-05-20T23:06:53.949976Z",
     "iopub.status.idle": "2022-05-20T23:06:59.622657Z",
     "shell.execute_reply": "2022-05-20T23:06:59.621792Z",
     "shell.execute_reply.started": "2022-05-20T23:06:53.950187Z"
    },
    "id": "wz7JepVilAkN",
    "outputId": "0652de28-9bd3-4ab7-c97c-55e6e11935e6",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "\n",
    "def downcast_floats(df):\n",
    "    floats = ['float32', 'float64']\n",
    "    float_features = list(df.select_dtypes(include=floats).columns)\n",
    "    for f in float_features:\n",
    "        df[f] = df[f].astype('float16')\n",
    "    return df\n",
    "    \n",
    "def load_dataset(label='train'):\n",
    "    if CFG.full or CFG.folds:\n",
    "        train_files = glob(os.path.join(CFG.train_path, \"train_*.pkl\"))\n",
    "        valid_files = glob(os.path.join(CFG.train_path, \"valid_*.pkl\"))\n",
    "        train_files = train_files + valid_files\n",
    "    else:\n",
    "        train_files = glob(os.path.join(CFG.train_path, f\"{label}_*.pkl\"))\n",
    "\n",
    "    train = list()\n",
    "    for filename in tqdm(train_files):\n",
    "        # load data\n",
    "        df = pd.read_pickle(filename)\n",
    "\n",
    "        # set features\n",
    "        features = list(df.select_dtypes(include=numerics).columns)\n",
    "        features.remove(CFG.target)\n",
    "\n",
    "        if CFG.debug:\n",
    "            df = df.sample(n = 10000, random_state = CFG.seed)\n",
    "            df = df.reset_index(drop = True)\n",
    "        df = downcast_floats(df)\n",
    "        train.append(df)\n",
    "\n",
    "    train = pd.concat(train, axis=0, ignore_index=True)\n",
    "    gc.collect()\n",
    "    \n",
    "    return train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add the rest matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if not CFG.full and not CFG.folds:\n",
    "#     all_matches_files = glob(os.path.join(CFG.train_path, \"all_matches_*.pkl\"))\n",
    "    \n",
    "#     all_matches = list()\n",
    "#     for filename in tqdm(all_matches_files):\n",
    "#         df = pd.read_pickle(filename)\n",
    "#         if CFG.debug:\n",
    "#             df = df.sample(n = 10000, random_state = CFG.seed)\n",
    "#             df = df.reset_index(drop = True)\n",
    "#         df = downcast_floats(df)\n",
    "#         all_matches.append(df)\n",
    "\n",
    "#     all_matches = pd.concat(all_matches, axis=0, ignore_index=True)\n",
    "    \n",
    "    \n",
    "# all_matches['label'] = 1\n",
    "# all_matches = all_matches[all_matches['id'] != all_matches['match_id']]\n",
    "# all_matches = all_matches[['id', 'match_id', 'label'] + features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add matches to train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# all_matches_ids = set(all_matches['id'].unique())\n",
    "\n",
    "# train_ids = set(train['id'].unique())\n",
    "# all_matches_train_ids = list(train_ids.intersection(all_matches_ids))\n",
    "\n",
    "# if not CFG.full and not CFG.folds:\n",
    "#     valid_ids = set(valid['id'].unique())\n",
    "#     all_matches_valid_ids = list(valid_ids.intersection(all_matches_ids))\n",
    "\n",
    "# all_matches = all_matches.set_index('id')\n",
    "# all_matches_train = all_matches.loc[all_matches_train_ids]\n",
    "# all_matches_train = all_matches_train.reset_index()\n",
    "# train = pd.concat([train, all_matches_train], axis=0, ignore_index=True)\n",
    "# train = train.drop_duplicates(['id', 'match_id'])\n",
    "# del train_ids, all_matches_ids, all_matches_train_ids\n",
    "\n",
    "# if not CFG.full and not CFG.folds:\n",
    "#     all_matches_valid = all_matches.loc[all_matches_valid_ids]\n",
    "#     all_matches_valid = all_matches_valid.reset_index()\n",
    "#     valid = pd.concat([valid, all_matches_valid], axis=0, ignore_index=True)\n",
    "#     valid = valid.drop_duplicates(['id', 'match_id'])\n",
    "#     del valid_ids, all_matches_valid_ids, all_matches_valid\n",
    "\n",
    "# del all_matches, all_matches_train\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase fraction of positive targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "# if CFG.pos_frac:\n",
    "#     train_pos_index = train[train['label'] == 1].index\n",
    "#     train_neg_index = train[train['label'] == 0].index\n",
    "#     train_neg_index = np.random.choice(train_neg_index, size=int(len(train_pos_index)*((1-CFG.pos_frac)/CFG.pos_frac)))\n",
    "#     train_pos_index = np.concatenate([train_pos_index, train_neg_index])\n",
    "#     np.random.shuffle(train_pos_index)\n",
    "#     train = train.loc[train_pos_index].reset_index(drop=True)\n",
    "#     del train_pos_index, train_neg_index\n",
    "#     gc.collect()\n",
    "\n",
    "#     if not CFG.full and not CFG.folds:\n",
    "#         valid_pos_index = valid[valid['label'] == 1].index\n",
    "#         valid_neg_index = valid[valid['label'] == 0].index\n",
    "#         valid_neg_index = np.random.choice(valid_neg_index, size=int(len(valid_pos_index)*((1-CFG.pos_frac)/CFG.pos_frac)))\n",
    "#         valid_pos_index = np.concatenate([valid_pos_index, valid_neg_index])\n",
    "#         np.random.shuffle(valid_pos_index)\n",
    "#         valid = valid.loc[valid_pos_index].reset_index(drop=True)\n",
    "#         del valid_pos_index, valid_neg_index\n",
    "#         gc.collect() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FYI: Objective functions can take additional arguments\n",
    "# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n",
    "\n",
    "def objective(trial):\n",
    "    dtrain = lgb.Dataset(train[features], label=train[CFG.target])\n",
    "    dvalid = lgb.Dataset(valid[features], label=valid[CFG.target])\n",
    "\n",
    "    param = {\n",
    "        'seed': CFG.seed,\n",
    "#         'device': 'gpu',\n",
    "#         'gpu_platform_id': 0,\n",
    "#         'gpu_device_id': 0,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': trial.suggest_categorical(\"boosting_type\", ['gbdt']),# 'dart', 'goss']),\n",
    "        'force_col_wise': False, # Use only with CPU devices\n",
    "        'subsample_for_bin': 300000, # Number of data that sampled to construct feature discrete bins; setting this \n",
    "                                     # to larger value will give better training result but may increase train time\n",
    "        'n_estimators': 200, #trial.suggest_int('n_estimators', 300, 1000),      \n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 3e-1),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256), # Max number of leaves in one tree\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255), # Max number of bins that feature values will be \n",
    "                                                           # bucketed in. small number of bins may reduce training \n",
    "                                                           # accuracy but may deal with overfitting\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0), # Randomly select a subset of features \n",
    "                                                                               # if feature_fraction < 1.0\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0), # Randomly select part of data without \n",
    "                                                                               # resampling if bagging_fraction < 1.0\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7), # Perform bagging at every k iteration\n",
    "        'min_data_in_leaf': trial.suggest_int('min_child_samples', 5, 64), # Minimal number of data in one leaf\n",
    "                                                                            # aliases: min_child_samples, \n",
    "        'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 1e-4, 1e-1), # Stop trying to split \n",
    "                                                                                               # leave if sum of it's\n",
    "                                                                                               # hessian less than k\n",
    "#         'cat_smooth': trial.suggest_float('cat_smooth', 10.0, 100.0), # this can reduce the effect of noises in \n",
    "#                                                                       # categorical features, especially for \n",
    "#                                                                       # categories with few data\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'auc')\n",
    "    gbm = lgb.train(\n",
    "        param, \n",
    "        dtrain, \n",
    "        valid_sets=[dvalid],\n",
    "        callbacks = [lgb.log_evaluation(10), \n",
    "                     lgb.early_stopping(stopping_rounds=30)]\n",
    "    )\n",
    "\n",
    "    # Evaluation\n",
    "    preds = gbm.predict(valid[features])\n",
    "    roc_auc = roc_auc_score(valid[CFG.target], preds)\n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "if CFG.optimize:\n",
    "    train = load_dataset('train')\n",
    "    valid = load_dataset('valid')\n",
    "    \n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\"\n",
    "    )\n",
    "    study.optimize(objective, timeout=12*3600)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "        \n",
    "    # Save study to dataframe\n",
    "    study_df = study.trials_dataframe()\n",
    "    study_df.to_csv('additional_data/optuna_lgbm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60cfcd50a4234476b5a3f23d765fc671",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a92f5625502479c97203311381e5d10",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if CFG.load_params:\n",
    "    lgb_params = pd.read_csv('additional_data/optuna_lgbm.csv')\n",
    "\n",
    "    param_cols = [c for c in lgb_params.columns if c.startswith('params_')]\n",
    "    lgb_params = lgb_params.sort_values('value', ascending=False)[param_cols].head(10)\n",
    "\n",
    "    best_params = list()\n",
    "\n",
    "    def param_to_set(row):\n",
    "        row_dict = {k[7:]: v for k, v in row.items()}\n",
    "        row_dict['seed'] = CFG.seed\n",
    "        row_dict['objective'] = 'binary'\n",
    "        row_dict['metric'] = 'auc'\n",
    "        row_dict['n_estimators'] = 1500\n",
    "        row_dict['verbose'] = -1\n",
    "    #     row_dict['device'] = 'gpu'\n",
    "    #     row_dict['gpu_platform_id'] = 0\n",
    "    #     row_dict['gpu_device_id'] = 0\n",
    "        best_params.append(row_dict)\n",
    "\n",
    "    params = lgb_params.apply(param_to_set, axis=1)\n",
    "else:\n",
    "    params = {\n",
    "         'seed': CFG.seed,\n",
    "         'boosting_type': 'gbdt',\n",
    "         'reg_alpha': 0,\n",
    "         'reg_lambda': 10,\n",
    "         'max_depth': 64,\n",
    "         'num_leaves': 256,\n",
    "         'learning_rate': 0.07,\n",
    "         'n_estimators': 500,\n",
    "         'min_child_samples': 20,\n",
    "         'subsample': 0.5,\n",
    "         'colsample_bytree': 0.5,\n",
    "         'colsample_bynode': 1,\n",
    "         'objective': 'binary',\n",
    "         'metric': 'auc',\n",
    "         'verbose': -1,\n",
    "         'seed': CFG.seed,\n",
    "         'subsample_freq': 1,\n",
    "         'is_unbalance': False,\n",
    "         'importance_type': 'gain'\n",
    "    }\n",
    "\n",
    "if CFG.test:\n",
    "    params['n_estimators'] = 200\n",
    "    \n",
    "if CFG.select_features:\n",
    "    # extract a sample of the data\n",
    "    train = load_dataset('train')\n",
    "    train = train.sample(frac=0.2, random_state=CFG.seed)\n",
    "    valid = load_dataset('valid')\n",
    "    valid = valid.sample(frac=0.2, random_state=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature importance\n",
    "\n",
    "## LOFO importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44bbf4f8ed0a4683b9720d338f1e3632",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "features_to_check = ['manhattan', 'euclidian', 'main_category_jaccard', 'main_category_overlap', \n",
    "                     'main_category_cosine', 'closest_city1', 'closest_city2', 'tfidf_trigram_name_cleaned',\n",
    "                     'tfidf_trigram_full_address_cleaned', 'p1_manhattan_mean', 'p2_manhattan_mean',\n",
    "                     'p1_manhattan_min', 'p2_manhattan_min', 'p1_manhattan_max',\n",
    "                     'p2_manhattan_max', 'p1_manhattan_rank', 'p2_manhattan_rank',\n",
    "                     'p1_euclidian_mean', 'p2_euclidian_mean', 'p1_euclidian_min',\n",
    "                     'p2_euclidian_min', 'p1_euclidian_max', 'p2_euclidian_max',\n",
    "                     'p1_euclidian_rank', 'p2_euclidian_rank']\n",
    "\n",
    "\n",
    "if CFG.select_features and CFG.selection_type=='lofo':\n",
    "    # define the validation scheme\n",
    "    cv = KFold(n_splits=2)\n",
    "    train = pd.concat([train, valid], ignore_index=True)\n",
    "    del valid\n",
    "    gc.collect()\n",
    "    # define the binary target and the features\n",
    "    dataset = lofo.Dataset(df=train, target=CFG.target, features=features_to_check)\n",
    "    # define the validation scheme and scorer\n",
    "    lofo_imp = lofo.LOFOImportance(dataset, scoring=\"roc_auc\", cv=cv, model=lgb.LGBMClassifier(**params))\n",
    "    # get the mean and standard deviation of the importances in pandas format\n",
    "    importance_df = lofo_imp.get_importance()\n",
    "    importance_df.to_csv('additional_data/importance_df.csv')\n",
    "    # plot the means and standard deviations of the importances\n",
    "    lofo.plot_importance(importance_df, figsize=(12, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='perm':   \n",
    "    # fit model\n",
    "    model=lgb.LGBMClassifier(**params)\n",
    "    model.fit(train[features], train[CFG.target], eval_set=(valid[features], valid[CFG.target]))\n",
    "    # get permutation importance\n",
    "    perm = PermutationImportance(model, random_state=CFG.seed).fit(valid[features], valid[CFG.target])\n",
    "    eli5.show_weights(perm, feature_names = features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='perm':   \n",
    "    train[features] = train[features].fillna(-9999)\n",
    "    # fit model\n",
    "    model=lgb.LGBMClassifier(**params)\n",
    "    # calculate importance\n",
    "    feature_selector = BorutaShap(importance_measure='shap', classification=True)\n",
    "    feature_selector.fit(X=train[features], y=train[CFG.target], n_trials=50, sample=False, train_or_test = 'test', normalize=True, verbose=True)\n",
    "    feature_selector.plot(which_features='all', figsize=(16,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='gain':   \n",
    "    train[features] = train[features].fillna(-9999)\n",
    "    # fit model\n",
    "    model=lgb.LGBMClassifier(**params)\n",
    "    # calculate importance\n",
    "    feature_selector = BorutaShap(importance_measure='gini', classification=True)\n",
    "    feature_selector.fit(X=train[features], y=train[CFG.target], n_trials=50, sample=False, train_or_test = 'test', normalize=True, verbose=True)\n",
    "    feature_selector.plot(which_features='all', figsize=(16,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='corr':\n",
    "    features_corr = train.fillna(0).corr()\n",
    "    # transform to low triangle matrix\n",
    "    for i in range(features_corr.shape[0]):\n",
    "        for j in range(features_corr.shape[1]):\n",
    "            if j >= i:\n",
    "                features_corr.iloc[i, j] = 0\n",
    "    # unstack\n",
    "    features_corr = features_corr.abs().unstack()\n",
    "    features_corr = features_corr.reset_index()\n",
    "    # select features with corr > 0 and sort them \n",
    "    features_corr = features_corr[features_corr[0] > 0]\n",
    "    features_corr = features_corr.sort_values(0, kind=\"quicksort\", ascending=False)\n",
    "    display(features_corr.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train and validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utils for postprocessing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:07:12.983819Z",
     "iopub.status.busy": "2022-05-20T23:07:12.983027Z",
     "iopub.status.idle": "2022-05-20T23:07:12.994514Z",
     "shell.execute_reply": "2022-05-20T23:07:12.993726Z",
     "shell.execute_reply.started": "2022-05-20T23:07:12.983695Z"
    },
    "id": "yHFNkcnglAkW",
    "outputId": "b886a788-4f08-468b-8050-17e92da005ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_id2poi(input_df: pd.DataFrame) -> dict:\n",
    "    return dict(zip(input_df['p1'], input_df['point_of_interest']))\n",
    "\n",
    "def get_poi2ids(input_df: pd.DataFrame) -> dict:\n",
    "    return input_df.groupby('point_of_interest')['p1'].apply(set).to_dict()\n",
    "\n",
    "def get_score(input_df: pd.DataFrame):\n",
    "    scores = []\n",
    "    id2poi = get_id2poi(input_df)\n",
    "    poi2ids = get_poi2ids(input_df)\n",
    "    for id_str, matches in zip(input_df['p1'].to_numpy(), input_df['matches'].to_numpy()):\n",
    "        targets = poi2ids[id2poi[id_str]]\n",
    "        preds = set(matches.split())\n",
    "        score = len((targets & preds)) / len((targets | preds))\n",
    "        scores.append(score)\n",
    "    scores = np.array(scores)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "def postprocess(df):\n",
    "    id2match = dict(zip(df[\"p1\"].values, df[\"matches\"].str.split()))\n",
    "\n",
    "    for match in df[\"matches\"].values:\n",
    "        match = match.split()\n",
    "        if len(match) == 1:        \n",
    "            continue\n",
    "\n",
    "        base = match[0]\n",
    "        for m in match[1:]:\n",
    "            if not base in id2match[m]:\n",
    "                id2match[m].append(base)\n",
    "    df[\"matches\"] = df[\"id\"].map(id2match).map(\" \".join)\n",
    "    \n",
    "    return df \n",
    "\n",
    "def get_matches(df, preds):\n",
    "    match_id = df[\"p2\"].values\n",
    "    matches = []\n",
    "\n",
    "    for df_id, pred, match_idx in tqdm(zip(df[\"p1\"], preds, match_id), total=df.shape[0]):\n",
    "        idx = np.round(pred)\n",
    "        if pred == 1:\n",
    "            matches.append(df_id + \" \" + match_idx)\n",
    "        else:\n",
    "            matches.append(df_id)\n",
    "    \n",
    "    df['matches'] = matches\n",
    "    df = postprocess(df)\n",
    "    \n",
    "    return df[['p1', 'matches', 'point_of_interest']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cc5dfd40012e4fa0a2a49b181d926118",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6609b82e6d7453394068fe468a0d306",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\tvalid_0's auc: 0.991258\n",
      "[20]\tvalid_0's auc: 0.992255\n",
      "[30]\tvalid_0's auc: 0.993076\n",
      "[40]\tvalid_0's auc: 0.993594\n",
      "[50]\tvalid_0's auc: 0.994064\n",
      "[60]\tvalid_0's auc: 0.994329\n",
      "[70]\tvalid_0's auc: 0.99458\n",
      "[80]\tvalid_0's auc: 0.99475\n",
      "[90]\tvalid_0's auc: 0.994869\n",
      "[100]\tvalid_0's auc: 0.994937\n",
      "[110]\tvalid_0's auc: 0.994977\n",
      "[120]\tvalid_0's auc: 0.995044\n",
      "[130]\tvalid_0's auc: 0.995074\n",
      "[140]\tvalid_0's auc: 0.995129\n",
      "[150]\tvalid_0's auc: 0.995145\n",
      "[160]\tvalid_0's auc: 0.995172\n",
      "[170]\tvalid_0's auc: 0.995195\n",
      "[180]\tvalid_0's auc: 0.995199\n",
      "[190]\tvalid_0's auc: 0.995233\n",
      "[200]\tvalid_0's auc: 0.995238\n",
      "[210]\tvalid_0's auc: 0.995303\n",
      "[220]\tvalid_0's auc: 0.995352\n",
      "[230]\tvalid_0's auc: 0.995359\n",
      "[240]\tvalid_0's auc: 0.99538\n",
      "[250]\tvalid_0's auc: 0.995401\n",
      "[260]\tvalid_0's auc: 0.995416\n",
      "[270]\tvalid_0's auc: 0.995427\n",
      "[280]\tvalid_0's auc: 0.995467\n",
      "[290]\tvalid_0's auc: 0.995474\n",
      "[300]\tvalid_0's auc: 0.99549\n",
      "[310]\tvalid_0's auc: 0.995515\n",
      "[320]\tvalid_0's auc: 0.99555\n",
      "[330]\tvalid_0's auc: 0.995568\n",
      "[340]\tvalid_0's auc: 0.995597\n",
      "[350]\tvalid_0's auc: 0.995615\n",
      "[360]\tvalid_0's auc: 0.995624\n",
      "[370]\tvalid_0's auc: 0.995643\n",
      "[380]\tvalid_0's auc: 0.995636\n",
      "[390]\tvalid_0's auc: 0.995656\n",
      "[400]\tvalid_0's auc: 0.995656\n",
      "[410]\tvalid_0's auc: 0.995665\n",
      "[420]\tvalid_0's auc: 0.995692\n",
      "[430]\tvalid_0's auc: 0.995694\n",
      "[440]\tvalid_0's auc: 0.995705\n",
      "[450]\tvalid_0's auc: 0.995715\n",
      "[460]\tvalid_0's auc: 0.995718\n",
      "[470]\tvalid_0's auc: 0.995728\n",
      "[480]\tvalid_0's auc: 0.995733\n",
      "[490]\tvalid_0's auc: 0.995738\n",
      "[500]\tvalid_0's auc: 0.995749\n",
      "[510]\tvalid_0's auc: 0.995755\n",
      "[520]\tvalid_0's auc: 0.995756\n",
      "[530]\tvalid_0's auc: 0.995769\n",
      "[540]\tvalid_0's auc: 0.995766\n",
      "[550]\tvalid_0's auc: 0.995777\n",
      "[560]\tvalid_0's auc: 0.995776\n",
      "[570]\tvalid_0's auc: 0.995774\n",
      "[580]\tvalid_0's auc: 0.995771\n",
      "[590]\tvalid_0's auc: 0.995776\n",
      "[600]\tvalid_0's auc: 0.995764\n",
      "Early stopping, best iteration is:\n",
      "[556]\tvalid_0's auc: 0.995784\n",
      "MAP: 0.9579725197554383\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e3e875105924b8298c07b119624ac25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24182861 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard is 0.876094\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9911073d72b4b51a812de65fc3cbde7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "021351120f4643a9bbaa839976c9102f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\tvalid_0's auc: 0.991581\n",
      "[20]\tvalid_0's auc: 0.992501\n",
      "[30]\tvalid_0's auc: 0.993166\n",
      "[40]\tvalid_0's auc: 0.993587\n",
      "[50]\tvalid_0's auc: 0.993937\n",
      "[60]\tvalid_0's auc: 0.994223\n",
      "[70]\tvalid_0's auc: 0.99446\n",
      "[80]\tvalid_0's auc: 0.994587\n",
      "[90]\tvalid_0's auc: 0.994712\n",
      "[100]\tvalid_0's auc: 0.994794\n",
      "[110]\tvalid_0's auc: 0.994832\n",
      "[120]\tvalid_0's auc: 0.994874\n",
      "[130]\tvalid_0's auc: 0.994896\n",
      "[140]\tvalid_0's auc: 0.994918\n",
      "[150]\tvalid_0's auc: 0.994956\n",
      "[160]\tvalid_0's auc: 0.99498\n",
      "[170]\tvalid_0's auc: 0.994988\n",
      "[180]\tvalid_0's auc: 0.995001\n",
      "[190]\tvalid_0's auc: 0.995027\n",
      "[200]\tvalid_0's auc: 0.995037\n",
      "[210]\tvalid_0's auc: 0.995049\n",
      "[220]\tvalid_0's auc: 0.995052\n",
      "[230]\tvalid_0's auc: 0.995069\n",
      "[240]\tvalid_0's auc: 0.995083\n",
      "[250]\tvalid_0's auc: 0.995096\n",
      "[260]\tvalid_0's auc: 0.995093\n",
      "[270]\tvalid_0's auc: 0.995107\n",
      "[280]\tvalid_0's auc: 0.995116\n",
      "[290]\tvalid_0's auc: 0.995123\n",
      "[300]\tvalid_0's auc: 0.995137\n",
      "[310]\tvalid_0's auc: 0.99514\n",
      "[320]\tvalid_0's auc: 0.995138\n",
      "[330]\tvalid_0's auc: 0.995137\n",
      "[340]\tvalid_0's auc: 0.995135\n",
      "[350]\tvalid_0's auc: 0.995145\n",
      "[360]\tvalid_0's auc: 0.995153\n",
      "[370]\tvalid_0's auc: 0.995152\n",
      "[380]\tvalid_0's auc: 0.995161\n",
      "[390]\tvalid_0's auc: 0.995149\n",
      "[400]\tvalid_0's auc: 0.995156\n",
      "[410]\tvalid_0's auc: 0.99516\n",
      "[420]\tvalid_0's auc: 0.995165\n",
      "[430]\tvalid_0's auc: 0.995168\n",
      "[440]\tvalid_0's auc: 0.995173\n",
      "[450]\tvalid_0's auc: 0.99517\n",
      "[460]\tvalid_0's auc: 0.995172\n",
      "[470]\tvalid_0's auc: 0.995178\n",
      "[480]\tvalid_0's auc: 0.995179\n",
      "[490]\tvalid_0's auc: 0.995174\n",
      "[500]\tvalid_0's auc: 0.99518\n",
      "[510]\tvalid_0's auc: 0.995188\n",
      "[520]\tvalid_0's auc: 0.995195\n",
      "[530]\tvalid_0's auc: 0.995193\n",
      "[540]\tvalid_0's auc: 0.995187\n",
      "[550]\tvalid_0's auc: 0.995189\n",
      "[560]\tvalid_0's auc: 0.995188\n",
      "Early stopping, best iteration is:\n",
      "[519]\tvalid_0's auc: 0.995196\n",
      "MAP: 0.956823731672553\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fadda11979c94ae2b362ba9d6f490b48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24175388 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jaccard is 0.876023\n"
     ]
    }
   ],
   "source": [
    "def pickle_save(obj, filename):\n",
    "    pickle.dump(obj, open(filename, 'wb'))\n",
    "\n",
    "def pickle_load(filename):\n",
    "    return pickle.load(open(filename, 'rb'))\n",
    "\n",
    "models = list()\n",
    "\n",
    "for idx, (train_label, val_label) in enumerate([('train', 'valid'), ('valid', 'train')]):\n",
    "    train_df = load_dataset(train_label)\n",
    "    val_df = load_dataset(val_label)\n",
    "\n",
    "    cat_features = [#\"main_category1\", \"main_category2\",\n",
    "                    #\"closest_city1\", \"closest_city2\",\n",
    "                    \"country1\", \"country2\", \n",
    "                    \"categories1\", \"categories2\"]\n",
    "    num_features = [x for x in train_df.columns\n",
    "                    if x not in ['p1', 'p2', 'match', 'main_category1', 'main_category2'] + cat_features]\n",
    "    target = \"match\"\n",
    "\n",
    "    lgbmc = LGBMClassifier(**params)\n",
    "\n",
    "    # Train\n",
    "    lgbmc.fit(train_df[num_features + cat_features],\n",
    "              train_df[target],\n",
    "              categorical_feature=cat_features,\n",
    "              eval_metric=\"auc\",\n",
    "              eval_set=(\n",
    "                  val_df[num_features + cat_features], val_df[target]),\n",
    "              callbacks = [lgb.log_evaluation(10), \n",
    "                           lgb.early_stopping(stopping_rounds=CFG.es_rounds)])\n",
    "\n",
    "    # Save model\n",
    "    pickle_save(lgbmc, f\"{CFG.model_dir}/lgbmc_fold{idx}.pkl\")\n",
    "\n",
    "    # Predict\n",
    "    val_df[\"predict_proba\"] = lgbmc.predict_proba(val_df[num_features + cat_features])[:, 1]\n",
    "    pickle_save(val_df[\"predict_proba\"].to_numpy(), f\"{CFG.model_dir}/lgbmc_outoffold{idx}.pkl\")\n",
    "\n",
    "    # Show MAP metrics\n",
    "    print(\"MAP:\", average_precision_score(val_df[\"match\"], val_df[\"predict_proba\"]))\n",
    "    \n",
    "    # Add POI column to validation dataset\n",
    "    data_root = 'foursquare_location_matching'\n",
    "    data = pd.read_csv(os.path.join(data_root, 'train.csv'))[['id', 'point_of_interest']]\n",
    "\n",
    "    val_df = val_df.merge(data, how='left', left_on='p1', right_on='id')\n",
    "\n",
    "    del data\n",
    "    gc.collect()\n",
    "    \n",
    "    # Calculate Jaccard\n",
    "    y_hat = np.where(val_df[\"predict_proba\"] < CFG.threshold, 0, 1) \n",
    "    res = get_matches(val_df, y_hat)\n",
    "    res = res.drop_duplicates()\n",
    "    cv = get_score(res)\n",
    "    print(f'Jaccard is {cv:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_importance(model):\n",
    "    importance_df = pd.DataFrame(model.feature_importances_, \n",
    "                                 index=num_features + cat_features, \n",
    "                                 columns=['importance'])\\\n",
    "                        .sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    plt.bar(importance_df.index, importance_df.importance)\n",
    "    plt.grid()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "# def plot_importances(models):\n",
    "#     importance_df = pd.DataFrame(models[0].feature_importances_, \n",
    "#                                  index=num_features, \n",
    "#                                  columns=['importance'])\\\n",
    "#                         .sort_values(\"importance\", ascending=False)\n",
    "\n",
    "#     plt.figure(figsize=(16, 8))\n",
    "#     plt.bar(importance_df.index, importance_df.importance)\n",
    "#     plt.grid()\n",
    "#     plt.xticks(rotation=90)\n",
    "#     plt.ylabel(\"importance\")\n",
    "#     plt.tight_layout()\n",
    "#     plt.show()\n",
    "    \n",
    "plot_importance(lgbmc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "# AUC: 0.995502/0.99511\n",
    "# IOU: 0.875165/0.874105\n",
    "# LB: 0.882\n",
    "\n",
    "# Add new features (closest_city, main_categories, manhattan, euclidian, TF-IDF of some text columns, etc.)\n",
    "# AUC: 0.995776/0.995172\n",
    "# IOU: 0.876292/0.874874\n",
    "# LB: \n",
    "\n",
    "# Fix encoder bug, \n",
    "# AUC: 0.995784/0.995196\n",
    "# IOU: 0.876094/0.876023\n",
    "# LB: "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
