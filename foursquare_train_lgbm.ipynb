{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:06:53.408122Z",
     "iopub.status.busy": "2022-05-20T23:06:53.407759Z",
     "iopub.status.idle": "2022-05-20T23:06:53.948805Z",
     "shell.execute_reply": "2022-05-20T23:06:53.947555Z",
     "shell.execute_reply.started": "2022-05-20T23:06:53.408094Z"
    },
    "id": "H5QntWoelAkH",
    "outputId": "31efe7df-24ff-40e8-8517-0c7174968413"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "import difflib\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode\n",
    "import multiprocessing\n",
    "from tqdm.auto import tqdm\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold, StratifiedGroupKFold\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 13\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = Namespace(\n",
    "    train = True,\n",
    "    full = False,\n",
    "    select_features = False,\n",
    "    find_thresh = False,\n",
    "    seed = 42,\n",
    "    debug = False,\n",
    "    validate = False,\n",
    "    target = \"label\",\n",
    "    n_neighbors = 20,\n",
    "    n_splits = 5,\n",
    "    threshold = 0.5,\n",
    "    train_path = 'train_dataset'\n",
    ")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "new_features = ['category_venn',\n",
    "                'euclidean',\n",
    "                'haversine',\n",
    "                'kdist_diff',\n",
    "                'kneighbors_mean',\n",
    "                'manhattan',\n",
    "                'kdist_name_country',\n",
    "                'kneighbors_name_country',\n",
    "                'kdist_address_country',\n",
    "                'kneighbors_address_country',\n",
    "               ]\n",
    "bad_featuers = ['name_clean', 'address_clean', 'phone_clean']\n",
    "    \n",
    "]\n",
    "    \n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:06:53.950215Z",
     "iopub.status.busy": "2022-05-20T23:06:53.949976Z",
     "iopub.status.idle": "2022-05-20T23:06:59.622657Z",
     "shell.execute_reply": "2022-05-20T23:06:59.621792Z",
     "shell.execute_reply.started": "2022-05-20T23:06:53.950187Z"
    },
    "id": "wz7JepVilAkN",
    "outputId": "0652de28-9bd3-4ab7-c97c-55e6e11935e6",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "42c6f3bbed14450d862c6d3fc1ce5887",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def downcast_floats(df):\n",
    "    floats = ['float32', 'float64']\n",
    "    float_features = list(df.select_dtypes(include=floats).columns)\n",
    "    for f in float_features:\n",
    "        df[f] = df[f].astype('float16')\n",
    "    return df\n",
    "    \n",
    "if CFG.full:\n",
    "    train_files = glob(os.path.join(CFG.train_path, \"train_*.parquet\"))\n",
    "    valid_files = glob(os.path.join(CFG.train_path, \"valid_*.parquet\"))\n",
    "    train_files = train_files + valid_files\n",
    "else:\n",
    "    train_files = glob(os.path.join(CFG.train_path, \"train_*.parquet\"))\n",
    "\n",
    "train = list()\n",
    "for filename in tqdm(train_files):\n",
    "    df = pd.read_parquet(filename)\n",
    "    df = downcast_floats(df)\n",
    "    train.append(df)\n",
    "\n",
    "train = pd.concat(train, axis=0, ignore_index=True)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f828fabe00814ad7b51295c41f0f6ea9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not CFG.full:\n",
    "    valid_files = glob(os.path.join(CFG.train_path, \"valid_*.parquet\"))\n",
    "\n",
    "    valid = list()\n",
    "    for filename in tqdm(valid_files):\n",
    "        df = pd.read_parquet(filename)\n",
    "        df = downcast_floats(df)\n",
    "        valid.append(df)\n",
    "\n",
    "    valid = pd.concat(valid, axis=0, ignore_index=True)\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if bad_features:\n",
    "#     train = train.drop(bad_features, axis=1)\n",
    "#     if not CFG.full:\n",
    "#         valid = valid.drop(bad_features, axis=1)\n",
    "        \n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "features = list(train.select_dtypes(include=numerics).columns)\n",
    "features.remove(CFG.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgbm(X_train, y_train, X_val, y_val, params=None, es_rounds=50, model_dir=None):\n",
    "    train_dataset = lgb.Dataset(X_train, y_train)\n",
    "    valid_dataset = lgb.Dataset(X_val, y_val)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set = train_dataset, \n",
    "        valid_sets = [train_dataset, valid_dataset],\n",
    "        callbacks = [lgb.log_evaluation(50), \n",
    "                     lgb.early_stopping(stopping_rounds=es_rounds),\n",
    "#                      init_model = gbm_init\n",
    "                    ]\n",
    "        )\n",
    "\n",
    "    file = f'fsq_lgbm_models_train_test/lgbm.pkl'\n",
    "    pickle.dump(model, open(file, 'wb'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict(model, threshold, X_val, y_val):\n",
    "    pred = model.predict(X_val)\n",
    "    cv = ((pred > threshold) == y_val).mean()\n",
    "    print(f\"ROC AUC: {cv}\")\n",
    "    return pred, cv\n",
    "\n",
    "def inference_lgbm(model, feat_df):\n",
    "    pred = np.array(model.predict(feat_df))\n",
    "    return pred\n",
    "\n",
    "def inference_lgbm_fold(models, feat_df):\n",
    "    pred = np.array([model.predict(feat_df) for model in models])\n",
    "    pred = np.mean(pred, axis=0)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.993762\tvalid_1's auc: 0.992778\n",
      "[100]\ttraining's auc: 0.994574\tvalid_1's auc: 0.993535\n",
      "[150]\ttraining's auc: 0.994958\tvalid_1's auc: 0.99365\n",
      "[200]\ttraining's auc: 0.99526\tvalid_1's auc: 0.993786\n",
      "[250]\ttraining's auc: 0.995463\tvalid_1's auc: 0.993856\n",
      "[300]\ttraining's auc: 0.995645\tvalid_1's auc: 0.99394\n",
      "[350]\ttraining's auc: 0.995803\tvalid_1's auc: 0.99401\n",
      "[400]\ttraining's auc: 0.99596\tvalid_1's auc: 0.994064\n",
      "[450]\ttraining's auc: 0.996081\tvalid_1's auc: 0.994097\n",
      "[500]\ttraining's auc: 0.996195\tvalid_1's auc: 0.994138\n",
      "[550]\ttraining's auc: 0.996302\tvalid_1's auc: 0.994169\n",
      "[600]\ttraining's auc: 0.996393\tvalid_1's auc: 0.994181\n",
      "[650]\ttraining's auc: 0.996481\tvalid_1's auc: 0.994192\n",
      "[700]\ttraining's auc: 0.996564\tvalid_1's auc: 0.994209\n",
      "[750]\ttraining's auc: 0.996638\tvalid_1's auc: 0.994214\n",
      "[800]\ttraining's auc: 0.99672\tvalid_1's auc: 0.994238\n",
      "[850]\ttraining's auc: 0.996802\tvalid_1's auc: 0.994262\n",
      "[900]\ttraining's auc: 0.996863\tvalid_1's auc: 0.994271\n",
      "[950]\ttraining's auc: 0.996932\tvalid_1's auc: 0.994285\n",
      "[1000]\ttraining's auc: 0.996998\tvalid_1's auc: 0.994294\n",
      "[1050]\ttraining's auc: 0.997067\tvalid_1's auc: 0.994301\n",
      "[1100]\ttraining's auc: 0.997123\tvalid_1's auc: 0.994304\n",
      "[1150]\ttraining's auc: 0.997179\tvalid_1's auc: 0.994317\n",
      "Early stopping, best iteration is:\n",
      "[1134]\ttraining's auc: 0.997163\tvalid_1's auc: 0.994319\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", module=\"lightgbm\")\n",
    "\n",
    "params = {\n",
    "    'seed': CFG.seed,\n",
    "#     'device': 'gpu',\n",
    "#     'gpu_platform_id': 0,\n",
    "#     'gpu_device_id': 0,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.2,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "#     'max_bin': 200,\n",
    "    'max_depth': 7,   \n",
    "    'num_leaves': 35, \n",
    "#     'min_data_in_leaf': 40,\n",
    "    'n_estimators': 1500, \n",
    "    'colsample_bytree': 0.9,\n",
    "    'snapshot_freq': 50,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "if CFG.select_features:\n",
    "    import lofo\n",
    "    from lofo import LOFOImportance, Dataset, plot_importance\n",
    "    # extract a sample of the data\n",
    "    train = train.sample(frac=0.15, random_state=CFG.seed)\n",
    "    valid = valid.sample(frac=0.15, random_state=CFG.seed)\n",
    "    train = pd.concat([train, valid], ignore_index=True)\n",
    "    del valid\n",
    "    gc.collect()\n",
    "    # define the validation scheme\n",
    "    cv = KFold(n_splits=2)\n",
    "    # define the binary target and the features\n",
    "    dataset = Dataset(df=train, target=CFG.target, features=new_features)\n",
    "    # define the validation scheme and scorer\n",
    "    lofo_imp = LOFOImportance(dataset, scoring=\"roc_auc\", cv=cv, model=lgb.LGBMClassifier(**params))\n",
    "    # get the mean and standard deviation of the importances in pandas format\n",
    "    importance_df = lofo_imp.get_importance()\n",
    "    importance_df.to_csv('importance_df.csv')\n",
    "    # plot the means and standard deviations of the importances\n",
    "    plot_importance(importance_df, figsize=(12, 20))\n",
    "elif CFG.full and CFG.train:\n",
    "    model = fit_lgbm(train[features], train[CFG.target], \n",
    "                     train[features], train[CFG.target], \n",
    "                     params=params, es_rounds=50)\n",
    "elif CFG.train:\n",
    "    model = fit_lgbm(train[features], train[CFG.target], \n",
    "                     valid[features], valid[CFG.target], \n",
    "                     params=params, es_rounds=50)\n",
    "else:\n",
    "    model_file = 'fsq_lgbm_models_train_test/lgbm1.pkl'\n",
    "    with open(model_file, 'rb') as f:\n",
    "        model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find optimal threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best threshold is 0\n"
     ]
    }
   ],
   "source": [
    "best_thr = 0\n",
    "best_cv = 0\n",
    "\n",
    "if CFG.find_thresh:\n",
    "    for thr in tqdm(np.arange(0.47, 0.54, 0.01)):\n",
    "        print(f'Threshold is {thr}')\n",
    "        _, cv = predict(model, thr, valid[features], valid[CFG.target])\n",
    "        if cv > best_cv:\n",
    "            best_cv = cv\n",
    "            best_thr = thr\n",
    "            \n",
    "print(f'Best threshold is {best_thr}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuctions for postprocessing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:07:12.983819Z",
     "iopub.status.busy": "2022-05-20T23:07:12.983027Z",
     "iopub.status.idle": "2022-05-20T23:07:12.994514Z",
     "shell.execute_reply": "2022-05-20T23:07:12.993726Z",
     "shell.execute_reply.started": "2022-05-20T23:07:12.983695Z"
    },
    "id": "yHFNkcnglAkW",
    "outputId": "b886a788-4f08-468b-8050-17e92da005ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_id2poi(input_df: pd.DataFrame) -> dict:\n",
    "    return dict(zip(input_df['id'], input_df['point_of_interest']))\n",
    "\n",
    "def get_poi2ids(input_df: pd.DataFrame) -> dict:\n",
    "    return input_df.groupby('point_of_interest')['id'].apply(set).to_dict()\n",
    "\n",
    "def get_score(input_df: pd.DataFrame):\n",
    "    scores = []\n",
    "    id2poi = get_id2poi(input_df)\n",
    "    poi2ids = get_poi2ids(input_df)\n",
    "    for id_str, matches in zip(input_df['id'].to_numpy(), input_df['matches'].to_numpy()):\n",
    "        targets = poi2ids[id2poi[id_str]]\n",
    "        preds = set(matches.split())\n",
    "        score = len((targets & preds)) / len((targets | preds))\n",
    "        scores.append(score)\n",
    "    scores = np.array(scores)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "def postprocess(df):\n",
    "    id2match = dict(zip(df[\"id\"].values, df[\"matches\"].str.split()))\n",
    "\n",
    "    for match in df[\"matches\"].values:\n",
    "        match = match.split()\n",
    "        if len(match) == 1:        \n",
    "            continue\n",
    "\n",
    "        base = match[0]\n",
    "        for m in match[1:]:\n",
    "            if not base in id2match[m]:\n",
    "                id2match[m].append(base)\n",
    "    df[\"matches\"] = df[\"id\"].map(id2match).map(\" \".join)\n",
    "    \n",
    "    return df \n",
    "\n",
    "def get_matches(df, preds):\n",
    "    match_id = df[\"match_id\"].values\n",
    "    matches = []\n",
    "\n",
    "    for df_id, pred, match_idx in tqdm(zip(df[\"id\"], preds, match_id), total=df.shape[0]):\n",
    "        idx = np.round(pred)\n",
    "        if idx == 1:\n",
    "            matches.append(df_id + \" \" + match_idx)\n",
    "        else:\n",
    "            matches.append(df_id)\n",
    "    \n",
    "    df['matches'] = matches\n",
    "    df = postprocess(df)\n",
    "    \n",
    "    return df[['id', 'matches', 'point_of_interest']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add POI column to validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.full:\n",
    "    data_root = 'foursquare_location_matching'\n",
    "    data = pd.read_csv(os.path.join(data_root, 'train.csv'))[['id', 'point_of_interest']]\n",
    "\n",
    "    valid = valid.merge(data, how='left', on='id')\n",
    "\n",
    "    del data\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predict matches and postprocess them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.9869706449667187\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d7ebb19ee4548a0bee6566ce409f465",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/26677299 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IOU: 0.859534\n",
      "CPU times: user 33min, sys: 4.92 s, total: 33min 5s\n",
      "Wall time: 5min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if CFG.find_thresh:\n",
    "    pred, cv = predict(model, best_thr, valid[features], valid[CFG.target])\n",
    "else:\n",
    "    pred, cv = predict(model, CFG.threshold, valid[features], valid[CFG.target])\n",
    "\n",
    "if not CFG.full:\n",
    "    res = get_matches(valid, pred)\n",
    "    res = res.drop_duplicates()\n",
    "    print(f\"IOU: {get_score(res):.6f}\")\n",
    "\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline:\n",
    "# ROC AUC: 0.986\n",
    "# IOU: 0.831\n",
    "\n",
    "# Add 'is_unbalance' parameter\n",
    "# ROC AUC: 0.967\n",
    "# IOU: 0.749\n",
    "\n",
    "# Sort categories\n",
    "# ROC AUC: 0.9863\n",
    "# IOU: 0.8325\n",
    "\n",
    "# Drop bad features\n",
    "# ROC AUC: 0.98656\n",
    "# IOU: 0.835467\n",
    "\n",
    "# Add main_category and closest_city\n",
    "# ROC AUC: 0.9868/0.987\n",
    "# IOU: 0.83869/0.838849\n",
    "\n",
    "# Clean name\n",
    "# ROC AUC: 0.98686/0.98697\n",
    "# IOU: 0.8392/0.8383\n",
    "\n",
    "# Add some many distance and text features\n",
    "# ROC AUC: 0.9871/\n",
    "# IOU: 0.839483/\n",
    "\n",
    "# Remove useless features\n",
    "# ROC AUC: 0.98717\n",
    "# IOU: 0.839719\n",
    "\n",
    "# Add KNN by name\n",
    "# ROC AUC: 0.985847\n",
    "# IOU: 0.857884\n",
    "\n",
    "# Add KNN by name and address\n",
    "# ROC AUC: 0.98697\n",
    "# IOU: 0.859534"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
