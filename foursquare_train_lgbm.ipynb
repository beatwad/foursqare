{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:06:53.408122Z",
     "iopub.status.busy": "2022-05-20T23:06:53.407759Z",
     "iopub.status.idle": "2022-05-20T23:06:53.948805Z",
     "shell.execute_reply": "2022-05-20T23:06:53.947555Z",
     "shell.execute_reply.started": "2022-05-20T23:06:53.408094Z"
    },
    "id": "H5QntWoelAkH",
    "outputId": "31efe7df-24ff-40e8-8517-0c7174968413"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/ubiquant/lib/python3.9/site-packages/lofo/lofo_importance.py:3: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import eli5\n",
    "import lofo\n",
    "import optuna\n",
    "import random\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "import difflib\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode\n",
    "import multiprocessing\n",
    "from tqdm.auto import tqdm\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "from BorutaShap import BorutaShap\n",
    "from sklearn.metrics import f1_score, fbeta_score, roc_auc_score\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from lofo import LOFOImportance, Dataset, plot_importance\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold, StratifiedGroupKFold\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", module=\"lightgbm\")\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 13\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = Namespace(\n",
    "    train = True,\n",
    "    full = True,\n",
    "    debug = False,\n",
    "    optimize = False,\n",
    "    select_features = False,\n",
    "    selection_type = 'corr', # feasible values: lofo, perm, shap, corr, gain\n",
    "    test = False,\n",
    "    folds = 0,\n",
    "    seed = 42,\n",
    "    pos_frac = 0,\n",
    "    target = 'label',\n",
    "    threshold = 0.5,\n",
    "    train_path = 'train_dataset',\n",
    "    model_dir = 'fsq_lgbm_models',\n",
    "    es_rounds = 50\n",
    ")\n",
    "\n",
    "# bad_features = [i for i in train.columns if i.endswith('cosine')]\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data\n",
    "\n",
    "## Load train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:06:53.950215Z",
     "iopub.status.busy": "2022-05-20T23:06:53.949976Z",
     "iopub.status.idle": "2022-05-20T23:06:59.622657Z",
     "shell.execute_reply": "2022-05-20T23:06:59.621792Z",
     "shell.execute_reply.started": "2022-05-20T23:06:53.950187Z"
    },
    "id": "wz7JepVilAkN",
    "outputId": "0652de28-9bd3-4ab7-c97c-55e6e11935e6",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e57a333742a441198ccc0a6a32d52df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def downcast_floats(df):\n",
    "    floats = ['float32', 'float64']\n",
    "    float_features = list(df.select_dtypes(include=floats).columns)\n",
    "    for f in float_features:\n",
    "        df[f] = df[f].astype('float16')\n",
    "    return df\n",
    "    \n",
    "if CFG.full or CFG.folds:\n",
    "    train_files = glob(os.path.join(CFG.train_path, \"train_*.parquet\"))\n",
    "    valid_files = glob(os.path.join(CFG.train_path, \"valid_*.parquet\"))\n",
    "    train_files = train_files + valid_files\n",
    "else:\n",
    "    train_files = glob(os.path.join(CFG.train_path, \"train_*.parquet\"))\n",
    "\n",
    "train = list()\n",
    "for filename in tqdm(train_files):\n",
    "    df = pd.read_parquet(filename)\n",
    "    if CFG.debug:\n",
    "        df = df.sample(n = 10000, random_state = CFG.seed)\n",
    "        df = df.reset_index(drop = True)\n",
    "    df = downcast_floats(df)\n",
    "    train.append(df)\n",
    "\n",
    "train = pd.concat(train, axis=0, ignore_index=True)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not CFG.full and not CFG.folds:\n",
    "    valid_files = glob(os.path.join(CFG.train_path, \"valid_*.parquet\"))\n",
    "\n",
    "    valid = list()\n",
    "    for filename in tqdm(valid_files):\n",
    "        df = pd.read_parquet(filename)\n",
    "        if CFG.debug:\n",
    "            df = df.sample(n = 10000, random_state = CFG.seed)\n",
    "            df = df.reset_index(drop = True)\n",
    "        df = downcast_floats(df)\n",
    "        valid.append(df)\n",
    "\n",
    "    valid = pd.concat(valid, axis=0, ignore_index=True)\n",
    "    \n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Increase fraction of positive targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1e+03 ns, sys: 1 µs, total: 2 µs\n",
      "Wall time: 5.01 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if CFG.pos_frac:\n",
    "    train_pos_index = train[train['label'] == 1].index\n",
    "    train_neg_index = train[train['label'] == 0].index\n",
    "    train_neg_index = np.random.choice(train_neg_index, size=int(len(train_pos_index)*((1-CFG.pos_frac)/CFG.pos_frac)))\n",
    "    train_pos_index = np.concatenate([train_pos_index, train_neg_index])\n",
    "    np.random.shuffle(train_pos_index)\n",
    "    train = train.loc[train_pos_index].reset_index(drop=True)\n",
    "    del train_pos_index, train_neg_index\n",
    "    gc.collect()\n",
    "\n",
    "    if not CFG.full and not CFG.folds:\n",
    "        valid_pos_index = valid[valid['label'] == 1].index\n",
    "        valid_neg_index = valid[valid['label'] == 0].index\n",
    "        valid_neg_index = np.random.choice(valid_neg_index, size=int(len(valid_pos_index)*((1-CFG.pos_frac)/CFG.pos_frac)))\n",
    "        valid_pos_index = np.concatenate([valid_pos_index, valid_neg_index])\n",
    "        np.random.shuffle(valid_pos_index)\n",
    "        valid = valid.loc[valid_pos_index].reset_index(drop=True)\n",
    "        del valid_pos_index, valid_neg_index\n",
    "        gc.collect() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Drop bad features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# if bad_features:\n",
    "#     train = train.drop(bad_features, axis=1)\n",
    "#     if not CFG.full and not CFG.folds:\n",
    "#         valid = valid.drop(bad_features, axis=1)\n",
    "        \n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "features = list(train.select_dtypes(include=numerics).columns)\n",
    "features.remove(CFG.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset by folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.folds > 0:\n",
    "    kf = StratifiedGroupKFold(n_splits=CFG.folds, shuffle=True, random_state=CFG.seed)\n",
    "    for i, (trn_idx, val_idx) in tqdm(enumerate(kf.split(train, train[\"label\"], train[\"id\"]))):\n",
    "        train.loc[val_idx, \"fold\"] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimize with Optuna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FYI: Objective functions can take additional arguments\n",
    "# (https://optuna.readthedocs.io/en/stable/faq.html#objective-func-additional-args).\n",
    "global global_preds\n",
    "\n",
    "def objective(trial):\n",
    "    global global_preds\n",
    "    dtrain = lgb.Dataset(train[features], label=train[CFG.target])\n",
    "    dvalid = lgb.Dataset(valid[features], label=valid[CFG.target])\n",
    "\n",
    "    param = {\n",
    "        'seed': CFG.seed,\n",
    "#         'device': 'gpu',\n",
    "#         'gpu_platform_id': 0,\n",
    "#         'gpu_device_id': 0,\n",
    "        'objective': 'binary',\n",
    "        'metric': 'auc',\n",
    "        'verbosity': -1,\n",
    "        'boosting_type': trial.suggest_categorical(\"boosting_type\", ['gbdt']),# 'dart', 'goss']),\n",
    "        'force_col_wise': False, # Use only with CPU devices\n",
    "        'subsample_for_bin': 300000, # Number of data that sampled to construct feature discrete bins; setting this \n",
    "                                     # to larger value will give better training result but may increase train time\n",
    "        'n_estimators': 300, #trial.suggest_int('n_estimators', 300, 1000),      \n",
    "        'learning_rate': trial.suggest_loguniform('learning_rate', 1e-3, 3e-1),\n",
    "        'lambda_l1': trial.suggest_float('lambda_l1', 1e-8, 10.0, log=True),\n",
    "        'lambda_l2': trial.suggest_float('lambda_l2', 1e-8, 10.0, log=True),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 256), # Max number of leaves in one tree\n",
    "        'max_bin': trial.suggest_int('max_bin', 32, 255), # Max number of bins that feature values will be \n",
    "                                                           # bucketed in. small number of bins may reduce training \n",
    "                                                           # accuracy but may deal with overfitting\n",
    "        'feature_fraction': trial.suggest_float('feature_fraction', 0.4, 1.0), # Randomly select a subset of features \n",
    "                                                                               # if feature_fraction < 1.0\n",
    "        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.4, 1.0), # Randomly select part of data without \n",
    "                                                                               # resampling if bagging_fraction < 1.0\n",
    "        'bagging_freq': trial.suggest_int('bagging_freq', 1, 7), # Perform bagging at every k iteration\n",
    "        'min_data_in_leaf': trial.suggest_int('min_child_samples', 5, 64), # Minimal number of data in one leaf\n",
    "                                                                            # aliases: min_child_samples, \n",
    "        'min_sum_hessian_in_leaf': trial.suggest_float('min_sum_hessian_in_leaf', 1e-4, 1e-1), # Stop trying to split \n",
    "                                                                                               # leave if sum of it's\n",
    "                                                                                               # hessian less than k\n",
    "#         'cat_smooth': trial.suggest_float('cat_smooth', 10.0, 100.0), # this can reduce the effect of noises in \n",
    "#                                                                       # categorical features, especially for \n",
    "#                                                                       # categories with few data\n",
    "    }\n",
    "\n",
    "    # Add a callback for pruning.\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(trial, 'auc')\n",
    "    gbm = lgb.train(\n",
    "        param, \n",
    "        dtrain, \n",
    "        valid_sets=[dvalid],\n",
    "        callbacks = [lgb.log_evaluation(100), \n",
    "                     lgb.early_stopping(stopping_rounds=50)]\n",
    "    )\n",
    "\n",
    "    # Evaluation\n",
    "    preds = gbm.predict(valid[features])\n",
    "    global_preds = preds\n",
    "    roc_auc = roc_auc_score(valid[CFG.target], preds)\n",
    "    return roc_auc\n",
    "\n",
    "\n",
    "if CFG.optimize:\n",
    "    study = optuna.create_study(\n",
    "        pruner=optuna.pruners.MedianPruner(n_warmup_steps=10), direction=\"maximize\"\n",
    "    )\n",
    "    study.optimize(objective, timeout=9*3600)\n",
    "\n",
    "    print(\"Number of finished trials: {}\".format(len(study.trials)))\n",
    "\n",
    "    print(\"Best trial:\")\n",
    "    trial = study.best_trial\n",
    "\n",
    "    print(\"  Value: {}\".format(trial.value))\n",
    "\n",
    "    print(\"  Params: \")\n",
    "    for key, value in trial.params.items():\n",
    "        print(\"    {}: {}\".format(key, value))\n",
    "        \n",
    "    # Save study to dataframe\n",
    "    study_df = study.trials_dataframe()\n",
    "    study_df.to_csv('optuna_lgbm.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lgb_f1_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.where(y_hat < 0.5, 0, 1)  \n",
    "    return 'f1', f1_score(y_true, y_hat), True\n",
    "\n",
    "def lgb_f2_score(y_hat, data):\n",
    "    y_true = data.get_label()\n",
    "    y_hat = np.where(y_hat < 0.5, 0, 1)  \n",
    "    return 'f2', fbeta_score(y_true, y_hat, beta=2), True\n",
    "\n",
    "def fit_lgbm(X_train, y_train, X_val, y_val, init_model=None, \n",
    "             params=None, es_rounds=50, num_iter=0):\n",
    "    train_dataset = lgb.Dataset(X_train, y_train)\n",
    "    valid_dataset = lgb.Dataset(X_val, y_val)\n",
    "\n",
    "    model = lgb.train(\n",
    "        params,\n",
    "        train_set = train_dataset, \n",
    "        valid_sets = [train_dataset, valid_dataset],\n",
    "        init_model = init_model,\n",
    "        callbacks = [lgb.log_evaluation(10), \n",
    "                     lgb.early_stopping(stopping_rounds=es_rounds),\n",
    "                    ]\n",
    "        )\n",
    "\n",
    "    file = f'{CFG.model_dir}/lgbm.pkl'\n",
    "    pickle.dump(model, open(file, 'wb'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def fit_lgbm_folds(X, y, folds, init_model=None, params=None, es_rounds=50, num_iter=0):\n",
    "    models = []\n",
    "    \n",
    "    for i in tqdm(range(CFG.folds)):\n",
    "        print(f\"== fold {i} ==\")\n",
    "        trn_idx = folds != i\n",
    "        val_idx = folds == i\n",
    "    \n",
    "        train_dataset = lgb.Dataset(X.iloc[trn_idx], y.iloc[trn_idx])\n",
    "        valid_dataset = lgb.Dataset(X.iloc[val_idx], y.iloc[val_idx])\n",
    "\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set = train_dataset, \n",
    "            valid_sets = [train_dataset, valid_dataset],\n",
    "            init_model = init_model,\n",
    "            callbacks = [lgb.log_evaluation(50), \n",
    "                         lgb.early_stopping(stopping_rounds=es_rounds),\n",
    "                        ]\n",
    "            )\n",
    "\n",
    "        models.append(model)\n",
    "    \n",
    "        file = f'{CFG.model_dir}/lgbm_fold_{i}.pkl'\n",
    "        pickle.dump(model, open(file, 'wb'))\n",
    "\n",
    "    return models\n",
    "\n",
    "def predict_(model, X_val, y_val, threshold):\n",
    "    pred = model.predict(X_val)\n",
    "    return pred\n",
    "\n",
    "def predict_folds(models, X, y, folds, threshold):\n",
    "    oof = np.zeros((len(y)), dtype=np.float64)\n",
    "    \n",
    "    for i in tqdm(range(CFG.folds)):\n",
    "        trn_idx = folds != i\n",
    "        val_idx = folds == i\n",
    "        \n",
    "        pred = models[i].predict(X.iloc[val_idx])\n",
    "        oof[val_idx] = pred\n",
    "    \n",
    "    return oof\n",
    "\n",
    "def show_metrics(pred, threshold, y):\n",
    "    y_hat = np.where(pred < threshold, 0, 1)  \n",
    "    acc = (y_hat == y).mean()\n",
    "    f1 = f1_score(y, y_hat)\n",
    "    f2 = fbeta_score(y, y_hat, beta=2)\n",
    "    return acc, f1, f2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load best LGBM parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgb_params = pd.read_csv('optuna_lgbm.csv')\n",
    "# lgb_params.to_pickle('LGBM_Optuna_params.pkl')\n",
    "\n",
    "param_cols = [c for c in lgb_params.columns if c.startswith('params_')]\n",
    "lgb_params = lgb_params.sort_values('value')[param_cols].head(10)\n",
    "\n",
    "best_params = list()\n",
    "\n",
    "def param_to_set(row):\n",
    "    row_dict = {k[7:]: v for k, v in row.items()}\n",
    "    row_dict['seed'] = CFG.seed\n",
    "    row_dict['objective'] = 'binary'\n",
    "    row_dict['metric'] = 'auc'\n",
    "    row_dict['n_estimators'] = 1500\n",
    "    row_dict['verbose'] = -1\n",
    "#     row_dict['device'] = 'gpu'\n",
    "#     row_dict['gpu_platform_id'] = 0\n",
    "#     row_dict['gpu_device_id'] = 0\n",
    "    best_params.append(row_dict)\n",
    "    \n",
    "x = lgb_params.apply(param_to_set, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\"ignore\", module=\"lightgbm\")\n",
    "\n",
    "# params = best_params[0]\n",
    "params = {\n",
    "    'seed': CFG.seed,\n",
    "#     'device': 'gpu',\n",
    "#     'gpu_platform_id': 0,\n",
    "#     'gpu_device_id': 0,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.2,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "    'max_depth': 7,   \n",
    "    'num_leaves': 35, \n",
    "    'n_estimators': 1200, \n",
    "    'colsample_bytree': 0.9,\n",
    "    'verbose': -1,\n",
    "}  \n",
    "\n",
    "if CFG.test:\n",
    "    params['n_estimators'] = 400\n",
    "    \n",
    "if CFG.select_features:\n",
    "    # extract a sample of the data\n",
    "    train = train.sample(frac=0.1, random_state=CFG.seed)\n",
    "    valid = valid.sample(frac=0.1, random_state=CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOFO importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='lofo':\n",
    "    # define the validation scheme\n",
    "    cv = KFold(n_splits=2)\n",
    "    train = pd.concat([train, valid], ignore_index=True)\n",
    "    del valid\n",
    "    gc.collect()\n",
    "    # define the binary target and the features\n",
    "    dataset = lofo.Dataset(df=train, target=CFG.target, features=features)\n",
    "    # define the validation scheme and scorer\n",
    "    lofo_imp = lofo.LOFOImportance(dataset, scoring=\"roc_auc\", cv=cv, model=lgb.LGBMClassifier(**params))\n",
    "    # get the mean and standard deviation of the importances in pandas format\n",
    "    importance_df = lofo_imp.get_importance()\n",
    "    importance_df.to_csv('importance_df.csv')\n",
    "    # plot the means and standard deviations of the importances\n",
    "    lofo.plot_importance(importance_df, figsize=(12, 20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Permutation importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='perm':   \n",
    "    # fit model\n",
    "    model=lgb.LGBMClassifier(**params)\n",
    "    model.fit(train[features], train[CFG.target], eval_set=(valid[features], valid[CFG.target]))\n",
    "    # get permutation importance\n",
    "    perm = PermutationImportance(model, random_state=CFG.seed).fit(valid[features], valid[CFG.target])\n",
    "    eli5.show_weights(perm, feature_names = features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SHAP importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='perm':   \n",
    "    train[features] = train[features].fillna(-9999)\n",
    "    # fit model\n",
    "    model=lgb.LGBMClassifier(**params)\n",
    "    # calculate importance\n",
    "    feature_selector = BorutaShap(importance_measure='shap', classification=True)\n",
    "    feature_selector.fit(X=train[features], y=train[CFG.target], n_trials=50, sample=False, train_or_test = 'test', normalize=True, verbose=True)\n",
    "    feature_selector.plot(which_features='all', figsize=(16,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gain importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='gain':   \n",
    "    train[features] = train[features].fillna(-9999)\n",
    "    # fit model\n",
    "    model=lgb.LGBMClassifier(**params)\n",
    "    # calculate importance\n",
    "    feature_selector = BorutaShap(importance_measure='gini', classification=True)\n",
    "    feature_selector.fit(X=train[features], y=train[CFG.target], n_trials=50, sample=False, train_or_test = 'test', normalize=True, verbose=True)\n",
    "    feature_selector.plot(which_features='all', figsize=(16,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check correlation between features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if CFG.select_features and CFG.selection_type=='corr':\n",
    "    features_corr = train.fillna(0).corr()\n",
    "    # transform to low triangle matrix\n",
    "    for i in range(features_corr.shape[0]):\n",
    "        for j in range(features_corr.shape[1]):\n",
    "            if j >= i:\n",
    "                features_corr.iloc[i, j] = 0\n",
    "    # unstack\n",
    "    features_corr = features_corr.abs().unstack()\n",
    "    features_corr = features_corr.reset_index()\n",
    "    # select features with corr > 0 and sort them \n",
    "    features_corr = features_corr[features_corr[0] > 0]\n",
    "    features_corr = features_corr.sort_values(0, kind=\"quicksort\", ascending=False)\n",
    "    display(features_corr.head(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48356386, 84)\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[10]\ttraining's auc: 0.98856\tvalid_1's auc: 0.98856\n",
      "[20]\ttraining's auc: 0.990731\tvalid_1's auc: 0.990731\n",
      "[30]\ttraining's auc: 0.991556\tvalid_1's auc: 0.991556\n",
      "[40]\ttraining's auc: 0.991979\tvalid_1's auc: 0.991979\n",
      "[50]\ttraining's auc: 0.992359\tvalid_1's auc: 0.992359\n",
      "[60]\ttraining's auc: 0.992634\tvalid_1's auc: 0.992634\n",
      "[70]\ttraining's auc: 0.992805\tvalid_1's auc: 0.992805\n",
      "[80]\ttraining's auc: 0.992984\tvalid_1's auc: 0.992984\n",
      "[90]\ttraining's auc: 0.993152\tvalid_1's auc: 0.993152\n",
      "[100]\ttraining's auc: 0.99324\tvalid_1's auc: 0.99324\n",
      "[110]\ttraining's auc: 0.993319\tvalid_1's auc: 0.993319\n",
      "[120]\ttraining's auc: 0.99339\tvalid_1's auc: 0.99339\n",
      "[130]\ttraining's auc: 0.993451\tvalid_1's auc: 0.993451\n",
      "[140]\ttraining's auc: 0.993501\tvalid_1's auc: 0.993501\n",
      "[150]\ttraining's auc: 0.993564\tvalid_1's auc: 0.993564\n",
      "[160]\ttraining's auc: 0.993667\tvalid_1's auc: 0.993667\n",
      "[170]\ttraining's auc: 0.993752\tvalid_1's auc: 0.993752\n",
      "[180]\ttraining's auc: 0.993802\tvalid_1's auc: 0.993802\n",
      "[190]\ttraining's auc: 0.993838\tvalid_1's auc: 0.993838\n",
      "[200]\ttraining's auc: 0.993877\tvalid_1's auc: 0.993877\n",
      "[210]\ttraining's auc: 0.993922\tvalid_1's auc: 0.993922\n",
      "[220]\ttraining's auc: 0.993979\tvalid_1's auc: 0.993979\n",
      "[230]\ttraining's auc: 0.994018\tvalid_1's auc: 0.994018\n",
      "[240]\ttraining's auc: 0.994058\tvalid_1's auc: 0.994058\n",
      "[250]\ttraining's auc: 0.994112\tvalid_1's auc: 0.994112\n",
      "[260]\ttraining's auc: 0.994163\tvalid_1's auc: 0.994163\n",
      "[270]\ttraining's auc: 0.994209\tvalid_1's auc: 0.994209\n",
      "[280]\ttraining's auc: 0.994241\tvalid_1's auc: 0.994241\n",
      "[290]\ttraining's auc: 0.994286\tvalid_1's auc: 0.994286\n",
      "[300]\ttraining's auc: 0.994315\tvalid_1's auc: 0.994315\n",
      "[310]\ttraining's auc: 0.994361\tvalid_1's auc: 0.994361\n",
      "[320]\ttraining's auc: 0.994389\tvalid_1's auc: 0.994389\n",
      "[330]\ttraining's auc: 0.994437\tvalid_1's auc: 0.994437\n",
      "[340]\ttraining's auc: 0.994471\tvalid_1's auc: 0.994471\n",
      "[350]\ttraining's auc: 0.994505\tvalid_1's auc: 0.994505\n",
      "[360]\ttraining's auc: 0.994539\tvalid_1's auc: 0.994539\n",
      "[370]\ttraining's auc: 0.994569\tvalid_1's auc: 0.994569\n",
      "[380]\ttraining's auc: 0.994612\tvalid_1's auc: 0.994612\n",
      "[390]\ttraining's auc: 0.994641\tvalid_1's auc: 0.994641\n",
      "[400]\ttraining's auc: 0.994678\tvalid_1's auc: 0.994678\n",
      "[410]\ttraining's auc: 0.994707\tvalid_1's auc: 0.994707\n",
      "[420]\ttraining's auc: 0.994736\tvalid_1's auc: 0.994736\n",
      "[430]\ttraining's auc: 0.994763\tvalid_1's auc: 0.994763\n",
      "[440]\ttraining's auc: 0.99479\tvalid_1's auc: 0.99479\n",
      "[450]\ttraining's auc: 0.994813\tvalid_1's auc: 0.994813\n",
      "[460]\ttraining's auc: 0.994829\tvalid_1's auc: 0.994829\n",
      "[470]\ttraining's auc: 0.994856\tvalid_1's auc: 0.994856\n",
      "[480]\ttraining's auc: 0.99488\tvalid_1's auc: 0.99488\n",
      "[490]\ttraining's auc: 0.994898\tvalid_1's auc: 0.994898\n",
      "[500]\ttraining's auc: 0.994922\tvalid_1's auc: 0.994922\n",
      "[510]\ttraining's auc: 0.994939\tvalid_1's auc: 0.994939\n",
      "[520]\ttraining's auc: 0.994956\tvalid_1's auc: 0.994956\n",
      "[530]\ttraining's auc: 0.994989\tvalid_1's auc: 0.994989\n",
      "[540]\ttraining's auc: 0.995003\tvalid_1's auc: 0.995003\n",
      "[550]\ttraining's auc: 0.995024\tvalid_1's auc: 0.995024\n",
      "[560]\ttraining's auc: 0.995045\tvalid_1's auc: 0.995045\n",
      "[570]\ttraining's auc: 0.995061\tvalid_1's auc: 0.995061\n",
      "[580]\ttraining's auc: 0.99508\tvalid_1's auc: 0.99508\n",
      "[590]\ttraining's auc: 0.995101\tvalid_1's auc: 0.995101\n",
      "[600]\ttraining's auc: 0.995124\tvalid_1's auc: 0.995124\n",
      "[610]\ttraining's auc: 0.995141\tvalid_1's auc: 0.995141\n",
      "[620]\ttraining's auc: 0.995164\tvalid_1's auc: 0.995164\n",
      "[630]\ttraining's auc: 0.995185\tvalid_1's auc: 0.995185\n",
      "[640]\ttraining's auc: 0.995208\tvalid_1's auc: 0.995208\n",
      "[650]\ttraining's auc: 0.995226\tvalid_1's auc: 0.995226\n",
      "[660]\ttraining's auc: 0.995247\tvalid_1's auc: 0.995247\n",
      "[670]\ttraining's auc: 0.995271\tvalid_1's auc: 0.995271\n",
      "[680]\ttraining's auc: 0.995287\tvalid_1's auc: 0.995287\n",
      "[690]\ttraining's auc: 0.9953\tvalid_1's auc: 0.9953\n",
      "[700]\ttraining's auc: 0.995319\tvalid_1's auc: 0.995319\n",
      "[710]\ttraining's auc: 0.995339\tvalid_1's auc: 0.995339\n",
      "[720]\ttraining's auc: 0.995358\tvalid_1's auc: 0.995358\n",
      "[730]\ttraining's auc: 0.995373\tvalid_1's auc: 0.995373\n",
      "[740]\ttraining's auc: 0.995395\tvalid_1's auc: 0.995395\n",
      "[750]\ttraining's auc: 0.995412\tvalid_1's auc: 0.995412\n",
      "[760]\ttraining's auc: 0.995428\tvalid_1's auc: 0.995428\n",
      "[770]\ttraining's auc: 0.99545\tvalid_1's auc: 0.99545\n",
      "[780]\ttraining's auc: 0.995468\tvalid_1's auc: 0.995468\n",
      "[790]\ttraining's auc: 0.99548\tvalid_1's auc: 0.99548\n",
      "[800]\ttraining's auc: 0.995499\tvalid_1's auc: 0.995499\n",
      "[810]\ttraining's auc: 0.995514\tvalid_1's auc: 0.995514\n",
      "[820]\ttraining's auc: 0.995528\tvalid_1's auc: 0.995528\n",
      "[830]\ttraining's auc: 0.995541\tvalid_1's auc: 0.995541\n",
      "[840]\ttraining's auc: 0.995552\tvalid_1's auc: 0.995552\n",
      "[850]\ttraining's auc: 0.995569\tvalid_1's auc: 0.995569\n",
      "[860]\ttraining's auc: 0.995584\tvalid_1's auc: 0.995584\n",
      "[870]\ttraining's auc: 0.995601\tvalid_1's auc: 0.995601\n",
      "[880]\ttraining's auc: 0.995614\tvalid_1's auc: 0.995614\n",
      "[890]\ttraining's auc: 0.995633\tvalid_1's auc: 0.995633\n",
      "[900]\ttraining's auc: 0.995648\tvalid_1's auc: 0.995648\n",
      "[910]\ttraining's auc: 0.995657\tvalid_1's auc: 0.995657\n",
      "[920]\ttraining's auc: 0.995671\tvalid_1's auc: 0.995671\n",
      "[930]\ttraining's auc: 0.995685\tvalid_1's auc: 0.995685\n",
      "[940]\ttraining's auc: 0.995697\tvalid_1's auc: 0.995697\n",
      "[950]\ttraining's auc: 0.995714\tvalid_1's auc: 0.995714\n",
      "[960]\ttraining's auc: 0.995729\tvalid_1's auc: 0.995729\n",
      "[970]\ttraining's auc: 0.995745\tvalid_1's auc: 0.995745\n",
      "[980]\ttraining's auc: 0.99576\tvalid_1's auc: 0.99576\n",
      "[990]\ttraining's auc: 0.995774\tvalid_1's auc: 0.995774\n",
      "[1000]\ttraining's auc: 0.995786\tvalid_1's auc: 0.995786\n",
      "[1010]\ttraining's auc: 0.995803\tvalid_1's auc: 0.995803\n",
      "[1020]\ttraining's auc: 0.995819\tvalid_1's auc: 0.995819\n",
      "[1030]\ttraining's auc: 0.995833\tvalid_1's auc: 0.995833\n",
      "[1040]\ttraining's auc: 0.995847\tvalid_1's auc: 0.995847\n",
      "[1050]\ttraining's auc: 0.995859\tvalid_1's auc: 0.995859\n",
      "[1060]\ttraining's auc: 0.99587\tvalid_1's auc: 0.99587\n",
      "[1070]\ttraining's auc: 0.995881\tvalid_1's auc: 0.995881\n",
      "[1080]\ttraining's auc: 0.995896\tvalid_1's auc: 0.995896\n",
      "[1090]\ttraining's auc: 0.995908\tvalid_1's auc: 0.995908\n",
      "[1100]\ttraining's auc: 0.995917\tvalid_1's auc: 0.995917\n",
      "[1110]\ttraining's auc: 0.99593\tvalid_1's auc: 0.99593\n",
      "[1120]\ttraining's auc: 0.995943\tvalid_1's auc: 0.995943\n",
      "[1130]\ttraining's auc: 0.995956\tvalid_1's auc: 0.995956\n",
      "[1140]\ttraining's auc: 0.995968\tvalid_1's auc: 0.995968\n",
      "[1150]\ttraining's auc: 0.995978\tvalid_1's auc: 0.995978\n",
      "[1160]\ttraining's auc: 0.995987\tvalid_1's auc: 0.995987\n",
      "[1170]\ttraining's auc: 0.995995\tvalid_1's auc: 0.995995\n",
      "[1180]\ttraining's auc: 0.996007\tvalid_1's auc: 0.996007\n",
      "[1190]\ttraining's auc: 0.996018\tvalid_1's auc: 0.996018\n",
      "[1200]\ttraining's auc: 0.996032\tvalid_1's auc: 0.996032\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[1200]\ttraining's auc: 0.996032\tvalid_1's auc: 0.996032\n"
     ]
    }
   ],
   "source": [
    "print(f'Train shape is {train.shape}')\n",
    "\n",
    "if CFG.folds and CFG.train:\n",
    "    models = fit_lgbm_folds(train[features], train[CFG.target], folds=train['fold'].values,\n",
    "                            params=params, es_rounds=CFG.es_rounds)\n",
    "elif CFG.full and CFG.train:\n",
    "    model = fit_lgbm(train[features], train[CFG.target], \n",
    "                     train[features], train[CFG.target], \n",
    "                     params=params, es_rounds=CFG.es_rounds)\n",
    "elif CFG.train:\n",
    "    assert train.shape[1] == valid.shape[1]\n",
    "    model = fit_lgbm(train[features], train[CFG.target], \n",
    "                     valid[features], valid[CFG.target], \n",
    "                     params=params, es_rounds=CFG.es_rounds)\n",
    "elif CFG.folds:\n",
    "    model_files = glob(os.path.join(CFG.model_dir, \"lgbm*.pkl\"))\n",
    "    models = list()\n",
    "    for model_file in model_files:\n",
    "        with open(model_file, 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "            models.append(model)\n",
    "else:\n",
    "    model_file = f'{CFG.model_dir}/lgbm.pkl'\n",
    "    with open(model_file, 'rb') as f:\n",
    "        model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate metrics for the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'valid' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_249534/3985864978.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalid\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mCFG\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'valid' is not defined"
     ]
    }
   ],
   "source": [
    "best_thr = 0.5\n",
    "best_cv = 0\n",
    "\n",
    "# if CFG.folds:\n",
    "#     X = train[features]\n",
    "#     y = train[CFG.target]\n",
    "# else:\n",
    "#     X = valid[features]\n",
    "#     y = valid[CFG.target]\n",
    "\n",
    "if CFG.folds:\n",
    "    pred = predict_folds(models, train[features], train[CFG.target], train['fold'].values, best_thr)\n",
    "    acc, f1, f2 = show_metrics(pred, best_thr, train[CFG.target])\n",
    "else:\n",
    "    pred = predict_(model, valid[features], valid[CFG.target], best_thr)      \n",
    "    acc, f1, f2 = show_metrics(pred, best_thr, valid[CFG.target])\n",
    "\n",
    "print(f'Best threshold is {best_thr}, Accuracy is {acc:.6f}, F1 score is {f1:.6f}, F2 score is {f2:.6f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuctions for postprocessing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:07:12.983819Z",
     "iopub.status.busy": "2022-05-20T23:07:12.983027Z",
     "iopub.status.idle": "2022-05-20T23:07:12.994514Z",
     "shell.execute_reply": "2022-05-20T23:07:12.993726Z",
     "shell.execute_reply.started": "2022-05-20T23:07:12.983695Z"
    },
    "id": "yHFNkcnglAkW",
    "outputId": "b886a788-4f08-468b-8050-17e92da005ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_id2poi(input_df: pd.DataFrame) -> dict:\n",
    "    return dict(zip(input_df['id'], input_df['point_of_interest']))\n",
    "\n",
    "def get_poi2ids(input_df: pd.DataFrame) -> dict:\n",
    "    return input_df.groupby('point_of_interest')['id'].apply(set).to_dict()\n",
    "\n",
    "def get_score(input_df: pd.DataFrame):\n",
    "    scores = []\n",
    "    id2poi = get_id2poi(input_df)\n",
    "    poi2ids = get_poi2ids(input_df)\n",
    "    for id_str, matches in zip(input_df['id'].to_numpy(), input_df['matches'].to_numpy()):\n",
    "        targets = poi2ids[id2poi[id_str]]\n",
    "        preds = set(matches.split())\n",
    "        score = len((targets & preds)) / len((targets | preds))\n",
    "        scores.append(score)\n",
    "    scores = np.array(scores)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "def postprocess(df):\n",
    "    id2match = dict(zip(df[\"id\"].values, df[\"matches\"].str.split()))\n",
    "\n",
    "    for match in df[\"matches\"].values:\n",
    "        match = match.split()\n",
    "        if len(match) == 1:        \n",
    "            continue\n",
    "\n",
    "        base = match[0]\n",
    "        for m in match[1:]:\n",
    "            if not base in id2match[m]:\n",
    "                id2match[m].append(base)\n",
    "    df[\"matches\"] = df[\"id\"].map(id2match).map(\" \".join)\n",
    "    \n",
    "    return df \n",
    "\n",
    "def get_matches(df, preds):\n",
    "    match_id = df[\"match_id\"].values\n",
    "    matches = []\n",
    "\n",
    "    for df_id, pred, match_idx in tqdm(zip(df[\"id\"], preds, match_id), total=df.shape[0]):\n",
    "        idx = np.round(pred)\n",
    "        if pred == 1:\n",
    "            matches.append(df_id + \" \" + match_idx)\n",
    "        else:\n",
    "            matches.append(df_id)\n",
    "    \n",
    "    df['matches'] = matches\n",
    "    df = postprocess(df)\n",
    "    \n",
    "    return df[['id', 'matches', 'point_of_interest']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add POI column to validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not CFG.full:\n",
    "    data_root = 'foursquare_location_matching'\n",
    "    data = pd.read_csv(os.path.join(data_root, 'train.csv'))[['id', 'point_of_interest']]\n",
    "\n",
    "    if CFG.folds:\n",
    "        valid = train.merge(data, how='left', on='id')\n",
    "    else:\n",
    "        valid = valid.merge(data, how='left', on='id')\n",
    "\n",
    "    del data\n",
    "    gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Find best threshold and calculate IOU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "best_thr = 0.5\n",
    "best_cv = 0\n",
    "\n",
    "if not CFG.full:\n",
    "#     for thr in tqdm(np.arange(0.4, 0.6, 0.01)):\n",
    "#         if thr == 0.5:\n",
    "#             continue\n",
    "    y_hat = np.where(pred < CFG.threshold, 0, 1) \n",
    "    res = get_matches(valid, y_hat)\n",
    "    res = res.drop_duplicates()\n",
    "    cv = get_score(res)\n",
    "    print(f'Threshold is {CFG.threshold:.3f}, score is {cv:.6f}')\n",
    "#     if cv > best_cv:\n",
    "#         best_cv = cv\n",
    "#         best_thr = thr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plot_importance(model):\n",
    "    importance_df = pd.DataFrame(model.feature_importance(), \n",
    "                                 index=features, \n",
    "                                 columns=['importance'])\\\n",
    "                        .sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    plt.subplots(figsize=(len(features) // 4, 5))\n",
    "    plt.bar(importance_df.index, importance_df.importance)\n",
    "    plt.grid()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_importances(models):\n",
    "    importance_df = pd.DataFrame(models[0].feature_importance(), \n",
    "                                 index=features, \n",
    "                                 columns=['importance'])\\\n",
    "                        .sort_values(\"importance\", ascending=False)\n",
    "\n",
    "    plt.subplots(figsize=(len(features) // 4, 5))\n",
    "    plt.bar(importance_df.index, importance_df.importance)\n",
    "    plt.grid()\n",
    "    plt.xticks(rotation=90)\n",
    "    plt.ylabel(\"importance\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "if CFG.folds:\n",
    "    plot_importances(models)\n",
    "else:\n",
    "    plot_importance(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline\n",
    "# IOU: 0.859097\n",
    "# LB: 0.858\n",
    "\n",
    "# 2 group folds\n",
    "# IOU: 0.859097/0.857005\n",
    "# LB: 0.863\n",
    "\n",
    "# 5-stratified folds\n",
    "# IOU: 0.882\n",
    "# LB: 0.862\n",
    "\n",
    "# 5-stratified group folds\n",
    "# IOU: 0.882\n",
    "# LB: 0.861\n",
    "\n",
    "# 5-stratified group folds, thr 0.43\n",
    "# IOU: 0.883\n",
    "# LB: 0.854\n",
    "\n",
    "# Return cluster feature, n_iter 1429/1183      \n",
    "# IOU: 0.859382/0.859301\n",
    "# LB: 0.865\n",
    "\n",
    "\n",
    "# Test baseline\n",
    "# IOU: 0.854927\n",
    "\n",
    "# Drop bad features\n",
    "# IOU:"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
