{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:06:53.408122Z",
     "iopub.status.busy": "2022-05-20T23:06:53.407759Z",
     "iopub.status.idle": "2022-05-20T23:06:53.948805Z",
     "shell.execute_reply": "2022-05-20T23:06:53.947555Z",
     "shell.execute_reply.started": "2022-05-20T23:06:53.408094Z"
    },
    "id": "H5QntWoelAkH",
    "outputId": "31efe7df-24ff-40e8-8517-0c7174968413"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "import re\n",
    "import sys\n",
    "import math\n",
    "import json\n",
    "import time\n",
    "import random\n",
    "import joblib\n",
    "import pickle\n",
    "import warnings\n",
    "import difflib\n",
    "import Levenshtein\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import lightgbm as lgb\n",
    "from glob import glob\n",
    "from pathlib import Path\n",
    "from unidecode import unidecode\n",
    "import multiprocessing\n",
    "from tqdm.auto import tqdm\n",
    "from argparse import Namespace\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.metrics.pairwise import haversine_distances\n",
    "from sklearn.model_selection import KFold, GroupKFold, StratifiedKFold, StratifiedGroupKFold\n",
    "\n",
    "plt.rcParams[\"font.size\"] = 13\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = Namespace(\n",
    "    kaggle = False,\n",
    "    select_features = False,\n",
    "    seed = 42,\n",
    "    debug = False,\n",
    "    validate = False,\n",
    "    target = \"label\",\n",
    "    n_neighbors = 20,\n",
    "    n_splits = 5,\n",
    "    train_path = 'train_dataset'\n",
    ")\n",
    "\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    \n",
    "bad_features = ['name_len_diff', 'state_jaro', 'state_encoded_lcs',\n",
    "                'address_encoded_gesh', 'state_gesh', 'city_encoded_nlcsk',\n",
    "                'categories_nlcsk', 'city_encoded_sim', 'state_leven',\n",
    "                'address_encoded_nlcsk', 'name_nleven', 'city_encoded_gesh',\n",
    "                'state_encoded_leven', 'city_encoded_jaro', 'country_lcs',\n",
    "                'city_encoded_len_diff', 'state_nlcs', 'url_jaro']\n",
    "    \n",
    "seed_everything(CFG.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:06:53.950215Z",
     "iopub.status.busy": "2022-05-20T23:06:53.949976Z",
     "iopub.status.idle": "2022-05-20T23:06:59.622657Z",
     "shell.execute_reply": "2022-05-20T23:06:59.621792Z",
     "shell.execute_reply.started": "2022-05-20T23:06:53.950187Z"
    },
    "id": "wz7JepVilAkN",
    "outputId": "0652de28-9bd3-4ab7-c97c-55e6e11935e6",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a942e5ee751c42b29be623f20c16e821",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_files = glob(os.path.join(CFG.train_path, \"train_*.parquet\"))\n",
    "\n",
    "train = list()\n",
    "for filename in tqdm(train_files):\n",
    "    df = pd.read_parquet(filename)\n",
    "    train.append(df)\n",
    "\n",
    "train = pd.concat(train, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d914c0ddf10c4ba29f6ab08c7d7f26c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_files = glob(os.path.join(CFG.train_path, \"valid_*.parquet\"))\n",
    "\n",
    "valid = list()\n",
    "for filename in tqdm(valid_files):\n",
    "    df = pd.read_parquet(filename)\n",
    "    valid.append(df)\n",
    "\n",
    "valid = pd.concat(valid, axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "if bad_features:\n",
    "    train = train.drop(bad_features, axis=1)\n",
    "    valid = valid.drop(bad_features, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerics = ['int8', 'int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "features = list(train.select_dtypes(include=numerics).columns)\n",
    "features.remove(CFG.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_lgbm(X_train, y_train, X_val, y_val, params=None, es_rounds=50, model_dir=None):\n",
    "    train_dataset = lgb.Dataset(X_train, y_train)\n",
    "    valid_dataset = lgb.Dataset(X_val, y_val)\n",
    "\n",
    "    if model_dir is None:\n",
    "        model = lgb.train(\n",
    "            params,\n",
    "            train_set = train_dataset, \n",
    "            valid_sets = [train_dataset, valid_dataset],\n",
    "            callbacks = [lgb.log_evaluation(50), \n",
    "                         lgb.early_stopping(stopping_rounds=es_rounds)],\n",
    "        )\n",
    "    else:\n",
    "        with open(f'{model_dir}/lgbm.pkl', 'rb') as f:\n",
    "            model = pickle.load(f)\n",
    "\n",
    "    file = f'fsq_lgbm_models_train_test/lgbm.pkl'\n",
    "    pickle.dump(model, open(file, 'wb'))\n",
    "\n",
    "    return model\n",
    "\n",
    "def predict(model, threshold, X_val, y_val):\n",
    "    pred = model.predict(X_val)\n",
    "    cv = ((pred > threshold) == y_val).mean()\n",
    "    print(f\"CV-accuracy: {cv}\")\n",
    "    return pred\n",
    "\n",
    "def inference_lgbm(model, feat_df):\n",
    "    pred = np.array(model.predict(feat_df))\n",
    "    return pred\n",
    "\n",
    "def inference_lgbm_fold(models, feat_df):\n",
    "    pred = np.array([model.predict(feat_df) for model in models])\n",
    "    pred = np.mean(pred, axis=0)\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split dataset for train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 50 rounds\n",
      "[50]\ttraining's auc: 0.993609\tvalid_1's auc: 0.99344\n",
      "[100]\ttraining's auc: 0.994307\tvalid_1's auc: 0.993899\n",
      "[150]\ttraining's auc: 0.994688\tvalid_1's auc: 0.994081\n",
      "[200]\ttraining's auc: 0.99494\tvalid_1's auc: 0.994158\n",
      "[250]\ttraining's auc: 0.995168\tvalid_1's auc: 0.994204\n",
      "[300]\ttraining's auc: 0.995353\tvalid_1's auc: 0.994225\n",
      "[350]\ttraining's auc: 0.995537\tvalid_1's auc: 0.994276\n",
      "[400]\ttraining's auc: 0.9957\tvalid_1's auc: 0.994319\n",
      "[450]\ttraining's auc: 0.995835\tvalid_1's auc: 0.994346\n",
      "[500]\ttraining's auc: 0.995947\tvalid_1's auc: 0.994347\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[500]\ttraining's auc: 0.995947\tvalid_1's auc: 0.994347\n",
      "\n",
      "CV-accuracy: 0.9865615976114233\n"
     ]
    }
   ],
   "source": [
    "warnings.filterwarnings(\"ignore\", module=\"lightgbm\")\n",
    "\n",
    "params = {\n",
    "    'seed': CFG.seed,\n",
    "#     'device': 'gpu',\n",
    "#     'gpu_platform_id': 0,\n",
    "#     'gpu_device_id': 0,\n",
    "    'objective': 'binary',\n",
    "    'metric': 'auc',\n",
    "    'learning_rate': 0.2,\n",
    "    'reg_alpha': 0.1,\n",
    "    'reg_lambda': 0.1,\n",
    "#     'max_bin': 200,\n",
    "    'max_depth': 7,   \n",
    "    'num_leaves': 35, \n",
    "#     'min_data_in_leaf': 40,\n",
    "    'n_estimators': 500, \n",
    "    'colsample_bytree': 0.9,\n",
    "    'verbose': -1\n",
    "}\n",
    "\n",
    "if CFG.select_features:\n",
    "    import lofo\n",
    "    from lofo import LOFOImportance, Dataset, plot_importance\n",
    "    # extract a sample of the data\n",
    "    train = train.sample(frac=0.1, random_state=CFG.seed)\n",
    "    valid = valid.sample(frac=0.1, random_state=CFG.seed)\n",
    "    train = pd.concat([train, valid], ignore_index=True)\n",
    "    del valid\n",
    "    gc.collect()\n",
    "    # define the validation scheme\n",
    "    cv = KFold(n_splits=2)\n",
    "    # define the binary target and the features\n",
    "    dataset = Dataset(df=train, target=CFG.target, features=features)\n",
    "    # define the validation scheme and scorer\n",
    "    lofo_imp = LOFOImportance(dataset, scoring=\"roc_auc\", cv=cv, model=lgb.LGBMClassifier(**params))\n",
    "    # get the mean and standard deviation of the importances in pandas format\n",
    "    importance_df = lofo_imp.get_importance()\n",
    "    # plot the means and standard deviations of the importances\n",
    "    plot_importance(importance_df, figsize=(12, 20))\n",
    "else:\n",
    "    model = fit_lgbm(train[features], train[CFG.target], \n",
    "                   valid[features], valid[CFG.target], \n",
    "                   params=params, es_rounds=50)\n",
    "    pred = predict(model, threshold=0.5, valid[features], valid[CFG.target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bad_features = importance_df.loc[importance_df.val_imp_0 < 0.00002, 'feature'].values\n",
    "# bad_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fuctions for postprocessing and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-05-20T23:07:12.983819Z",
     "iopub.status.busy": "2022-05-20T23:07:12.983027Z",
     "iopub.status.idle": "2022-05-20T23:07:12.994514Z",
     "shell.execute_reply": "2022-05-20T23:07:12.993726Z",
     "shell.execute_reply.started": "2022-05-20T23:07:12.983695Z"
    },
    "id": "yHFNkcnglAkW",
    "outputId": "b886a788-4f08-468b-8050-17e92da005ca",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def get_id2poi(input_df: pd.DataFrame) -> dict:\n",
    "    return dict(zip(input_df['id'], input_df['point_of_interest']))\n",
    "\n",
    "def get_poi2ids(input_df: pd.DataFrame) -> dict:\n",
    "    return input_df.groupby('point_of_interest')['id'].apply(set).to_dict()\n",
    "\n",
    "def get_score(input_df: pd.DataFrame):\n",
    "    scores = []\n",
    "    id2poi = get_id2poi(input_df)\n",
    "    poi2ids = get_poi2ids(input_df)\n",
    "    for id_str, matches in zip(input_df['id'].to_numpy(), input_df['matches'].to_numpy()):\n",
    "        targets = poi2ids[id2poi[id_str]]\n",
    "        preds = set(matches.split())\n",
    "        score = len((targets & preds)) / len((targets | preds))\n",
    "        scores.append(score)\n",
    "    scores = np.array(scores)\n",
    "    \n",
    "    return scores.mean()\n",
    "\n",
    "def postprocess(df):\n",
    "    id2match = dict(zip(df[\"id\"].values, df[\"matches\"].str.split()))\n",
    "\n",
    "    for match in df[\"matches\"].values:\n",
    "        match = match.split()\n",
    "        if len(match) == 1:        \n",
    "            continue\n",
    "\n",
    "        base = match[0]\n",
    "        for m in match[1:]:\n",
    "            if not base in id2match[m]:\n",
    "                id2match[m].append(base)\n",
    "    df[\"matches\"] = df[\"id\"].map(id2match).map(\" \".join)\n",
    "    \n",
    "    return df \n",
    "\n",
    "def get_matches(df, preds):\n",
    "    match_id = df[\"match_id\"].values\n",
    "    matches = []\n",
    "\n",
    "    for df_id, pred, match_idx in tqdm(zip(df[\"id\"], preds, match_id), total=df.shape[0]):\n",
    "        idx = np.round(pred)\n",
    "        if idx == 1:\n",
    "            matches.append(df_id + \" \" + match_idx)\n",
    "        else:\n",
    "            matches.append(df_id)\n",
    "    \n",
    "    df['matches'] = matches\n",
    "    df = postprocess(df)\n",
    "    \n",
    "    return df[['id', 'matches', 'point_of_interest']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add POI column to validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if CFG.kaggle:\n",
    "    data_root = '../input/foursquare-location-matching'\n",
    "else:\n",
    "    data_root = 'foursquare_location_matching'\n",
    "data = pd.read_csv(os.path.join(data_root, 'train.csv'))[['id', 'point_of_interest']]\n",
    "\n",
    "valid = valid.merge(data, how='left', on='id')\n",
    "\n",
    "del data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Predict matches and postprocess them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bd5ffa0efbb44f39dddd9b48bce1ae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/13917577 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV: 0.835467\n",
      "CPU times: user 1min 32s, sys: 776 ms, total: 1min 33s\n",
      "Wall time: 1min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "res = get_matches(valid, pred)\n",
    "res = res.drop_duplicates()\n",
    "print(f\"CV: {get_score(res):.6f}\")\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baseline:\n",
    "# AUC: 0.986\n",
    "# CV: 0.831\n",
    "\n",
    "# Add 'is_unbalance' parameter\n",
    "# acc: 0.967\n",
    "# CV: 0.749\n",
    "\n",
    "# Sort categories\n",
    "# acc: 0.9863\n",
    "# CV: 0.8325\n",
    "\n",
    "# Drop bad features\n",
    "# acc: 0.98656\n",
    "# CV: 0.835467"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Further ideas\n",
    "\n",
    "- add ntlk.edit_distance to your features\n",
    "- add new KNN from this notebook: https://www.kaggle.com/code/ragnar123/flm-xlmroberta-inference-baseline\n",
    "- add manhattan distance and euqlidian distance\n",
    "- increase number of nearest neighbours to a very high value (like 50-100-200), so you will be able to find more matches\n",
    "- create text column, use BERT to categorize https://www.kaggle.com/code/lunapandachan/foursquare-s-bert-labo-note#V3-Labeled-train\n",
    "\n",
    "- how to handle missing data https://www.kaggle.com/code/parulpandey/a-guide-to-handling-missing-values-in-python\n",
    "- mean/median/std encode features\n",
    "\n",
    "- use Cat2Vec to calculate categories similarity https://www.kaggle.com/code/aerdem4/foursquare-cat2vec/notebook\n",
    "\n",
    "\n",
    "- Optuna!\n",
    "\n",
    "\n",
    "- try XLMRoberta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "- change min_data_in_leaf and try to retrain with CPU "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
